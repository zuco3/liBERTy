{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637feaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: filelock in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: sacremoses in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: click in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!apt install swig\n",
    "# Sentencepieceのインストール\n",
    "!pip install sentencepiece\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10781bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (1.12.1)\r\n",
      "Requirement already satisfied: typing_extensions in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torch) (4.3.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b527e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41cb2c",
   "metadata": {},
   "source": [
    "## data shori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af750c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = '/export/livedoor' \n",
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|※|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|：|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c7760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/it-life-hack']\n",
    "target_genre = [\"dokujo-tsushin\", \"it-life-hack\"] \n",
    "#directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/peachy']\n",
    "#target_genre = [\"dokujo-tsushin\", \"peachy\"] \n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "        #if os.path.isfile(f):\n",
    "        #    print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "357bffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "\n",
    "df_ = pd.read_csv(\"summary_set_dokujo_it.tsv\", \n",
    "#                 delimiter='\\t', header=None, names=['summaries'])\n",
    "\n",
    "#df_ = pd.read_csv(\"summary_set_dokujo_peachy.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['summaries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b51fb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1740,), (1740,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.label.values\n",
    "summaries = df_.summaries.values\n",
    "labels.shape, summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1a6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大単語数:  72\n",
      "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
     ]
    }
   ],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    # Tokenizeで分割\n",
    "    token_words = tokenizer.tokenize(summa)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(token_words))\n",
    "# 最大の値を確認\n",
    "print('最大単語数: ', max(max_len))\n",
    "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777b2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  思いがけないことがある人間は、未来を教えてくれることがある。\n",
      "Token IDs: tensor([    9,  2969,    12, 18143,  1272,   858,    11,     7,  3638, 15718,\n",
      "        17379,  1272,     8,     2,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        summa,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = 50,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    \n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', summaries[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d99dbcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数：1540\n",
      "検証データ数:　172 \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# データセットクラスの作成\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 90%地点のIDを取得\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# データセットを分割\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数：{}'.format(train_size))\n",
    "print('検証データ数:　{} '.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "\n",
    "# 訓練データローダー\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "# 検証データローダー\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9fdb391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 22:12:06.927972: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 22:12:07.036540: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-14 22:12:07.395944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-14 22:12:07.395988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-14 22:12:07.395992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "# モデルをGPUへ転送\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8681226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 訓練パートの定義\n",
    "def train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss\n",
    "\n",
    "# テストパートの定義\n",
    "def validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ebb09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "max_epoch = 10\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train_ = train(model)\n",
    "    test_ = train(model)\n",
    "    train_loss_.append(train_)\n",
    "    test_loss_.append(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7e4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7048611111111112\n"
     ]
    }
   ],
   "source": [
    "# accuracy keisan\n",
    "\n",
    "import statistics\n",
    "\n",
    "#correct = 0\n",
    "test_accuracy = []\n",
    "\n",
    "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
    "\n",
    "model.eval()# 訓練モードをオフ\n",
    "for batch in validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        \n",
    "        test_accuracy.append((torch.argmax(preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)\n",
    "        \n",
    "print(statistics.mean(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b92e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力:SequenceClassifierOutput(loss=None, logits=tensor([[ 3.7722, -4.2100],\n",
      "        [-4.7970,  4.7886],\n",
      "        [-4.5730,  4.7843],\n",
      "        [ 0.4506, -0.5676],\n",
      "        [-4.1807,  4.3323],\n",
      "        [ 4.6500, -4.8177],\n",
      "        [-4.7070,  4.7666],\n",
      "        [-4.8782,  4.9630],\n",
      "        [ 4.7773, -5.0688],\n",
      "        [ 4.4903, -4.8129],\n",
      "        [-4.7947,  4.9347],\n",
      "        [ 0.5713, -0.3180]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の確認\n",
    "print(f'出力:{preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7425ef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_0</th>\n",
       "      <th>logit_1</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.772218</td>\n",
       "      <td>-4.209967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.797009</td>\n",
       "      <td>4.788573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.573005</td>\n",
       "      <td>4.784321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450601</td>\n",
       "      <td>-0.567594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.180709</td>\n",
       "      <td>4.332259</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logit_0   logit_1  pred_label  true_label\n",
       "0  3.772218 -4.209967           0           1\n",
       "1 -4.797009  4.788573           1           1\n",
       "2 -4.573005  4.784321           1           1\n",
       "3  0.450601 -0.567594           0           1\n",
       "4 -4.180709  4.332259           1           0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比較しやすい様にpd.dataframeへ整形\n",
    "import numpy as np\n",
    "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
    "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
    "## np.argmaxで大き方の値を取得\n",
    "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5680f066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_loss_)), train_loss_, label=\"Train\")\n",
    "plt.plot(range(len(test_loss_)), test_loss_, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()  # ラベルがあるときは、きちんとplt.show()を呼び出すこと"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
