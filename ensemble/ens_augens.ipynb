{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wcOk2ZzAAQr"
   },
   "source": [
    "# Hugging Face Library 'Transformer'およびT5Tokenizerのダウンロード\n",
    "\n",
    "参考(https://qiita.com/takubb/items/fd972f0ac3dba909c293)これを基に改造し、最新のGoogle Colaboratoryで動作するようにした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0b407dd3170f4f55be7f8708c59d262b",
      "5616789e354d45699ea2040757dbd5c3",
      "d6bc8aac6ca74bff92bba66f17c20b00",
      "96fb1e06ef4349b5b6a071be230a711c",
      "8d05e54e5fc644d2a3c974758c5e439c",
      "9a20acb0a8fc4320af5a849c9d780649",
      "45555846fc9746af9a06d76c6c9aee1b",
      "a0880f15772d4156a9eb94d6314c2d9e",
      "d337eb6795e241389d9b35805a59fc22",
      "efd4beed83d947b9a5eec5918dcd2319",
      "1aff4434a10549e387f749140d4721f4",
      "73fb8df2799443d996d165878dc526a8",
      "c9f368ede2d24e3095242e9a3cf8c545",
      "4535f833bfac4540a8add9686f623b54",
      "7803695cfa5742bf85208ee04193acb0",
      "423c0b6849204bbc96c7b039633373f9",
      "937dd0c1d06e4d69824b7be991cc52f0",
      "11cc64e4ce0843ae88a651762d68b844",
      "9279616c547b47de92a436ebb026fd79",
      "b3910389daf34e31af5f33ef7d539625",
      "d808ec79b0dd465a82077ca7f2c8feb6",
      "d2a46f9221b14f86a3330510812f258e",
      "dd6aadfe79224713b5a47dd108ff71b9",
      "cfd1b9e85db447fbaf01f66f6f0f6429",
      "705cf2ba17614d51853eeb9dfc74d540",
      "83cf06c42be34c068dbbf6fcc5cfd6d5",
      "9a9b67b9ebf94a13a95e759a696c884f",
      "2dc2139703bb4448969390f2a91e00f6",
      "46351ebb1bfd41b5b9fbc4de40e218e3",
      "3994b8f69c284d758c5f04deeb3fcca1",
      "08a0764a15bb4b45ab9bfdbe3a02c318",
      "f629f372d73b44efb31e8d7c5a45d4cd",
      "93c25b4c96e64fecbb7f569527e50722"
     ]
    },
    "executionInfo": {
     "elapsed": 30796,
     "status": "ok",
     "timestamp": 1661865111605,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "DJ__bXJq_06p",
    "outputId": "b2d9fbba-45cc-4348-fadf-7b15798ffd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing_extensions in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: transformers in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: sacremoses in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: filelock in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: joblib in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: six in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.1.96)\n",
      "Requirement already satisfied: mecab-python3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (1.0.5)\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "# !pip install torch\n",
    "!pip install torchvision\n",
    "!pip install transformers\n",
    "#!apt install swig\n",
    "# Sentencepieceのインストール\n",
    "!pip install sentencepiece\n",
    "!pip install mecab-python3\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "import gzip\n",
    "import shutil\n",
    "import sqlite3\n",
    "import random\n",
    "from math import ceil\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import torchvision\n",
    "import statistics\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import pickle\n",
    "import statistics\n",
    "import MeCab\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpCa2h0oAU51"
   },
   "source": [
    "# PyTorchとGPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5548,
     "status": "ok",
     "timestamp": 1661865117146,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "hLV4lS8CAWCZ",
    "outputId": "6fa5cea1-0ec6-4aa3-82d5-53328e8b1c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation kansuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synreplace - replace kasho kosuu\n",
    "# randinsert - tasu kotoba no kazu\n",
    "# randdelete - delete kakuritsu\n",
    "# randswap - swap kaisuu\n",
    "\n",
    "class synreplace(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        self.model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "    def __call__(self, textlist):\n",
    "        # textlist: honbun no list\n",
    "        textlen = torch.where(textlist == 3)[0][0]\n",
    "        for n in range(self.num):\n",
    "            # chikan shiro\n",
    "            masked_idx = random.randint(2, textlen-1)\n",
    "            textlist[masked_idx] = 6\n",
    "            # convert to tensor\n",
    "            token_tensor = torch.tensor(textlist)\n",
    "            # get the top 10 predictions of the masked token\n",
    "            self.model = self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(torch.unsqueeze(token_tensor, 0))\n",
    "                predictions = outputs[0][0, masked_idx].topk(1)\n",
    "            for i, index_t in enumerate(predictions.indices):\n",
    "                index = index_t.item()\n",
    "            textlist[masked_idx] = index\n",
    "        return textlist\n",
    "\n",
    "class randinsert(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        for n in range(self.num):\n",
    "            insword = textlist[random.randint(1,len(textlist)-1)]\n",
    "            i = random.randint(1,len(textlist)-1)\n",
    "#            print('len: ', len(textlist))\n",
    "#            print(i)\n",
    "            while textlist[i] == 3:\n",
    "                i = random.randint(1,len(textlist)-1)\n",
    "#                print(i)\n",
    "            textlist = torch.cat([textlist[0:i], torch.tensor([insword]), textlist[i:-1]])\n",
    "        return textlist\n",
    "\n",
    "class randdelete(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "#        print(textlist.shape)\n",
    "        for i in range(3,len(textlist)-1):\n",
    "            if textlist[i] == 3:\n",
    "                continue\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < self.num:\n",
    "#                textlist.pop(i)\n",
    "                textlist = torch.cat([textlist[0:i], textlist[i+1:], torch.tensor([3])])\n",
    "#                print(textlist)\n",
    "        return textlist\n",
    "\n",
    "class randswap(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        counter = 0\n",
    "        #rs_sents = np.zeros(len(textlist), dtype=object)\n",
    "        for i in range(len(textlist)):\n",
    "            while self.num > counter:\n",
    "                box = 0\n",
    "                random_idx_1 = random.randint(1, len(textlist)-1)\n",
    "                while textlist[random_idx_1] == 3:\n",
    "                    random_idx_1 = random.randint(0, len(textlist)-1)\n",
    "                random_idx_2 = random.randint(1, len(textlist)-1)\n",
    "                while random_idx_1 == random_idx_2 or textlist[random_idx_2] == 3:\n",
    "                    random_idx_2 = random.randint(0, len(textlist)-1)\n",
    "                    # print(random_idx_1, random_idx_2)\n",
    "                box = textlist[random_idx_1]\n",
    "                textlist[random_idx_1] = textlist[random_idx_2]\n",
    "                textlist[random_idx_2] = box\n",
    "                counter += 1\n",
    "        return textlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tensor Dataset\n",
    "https://stackoverflow.com/questions/55588201/pytorch-transforms-on-tensordataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブドアニュースコーパスをダウンロード\n",
    "\n",
    "    ダウンロードしたファイルは圧縮（tar.gz形式）ファイル\n",
    "    様々なジャンル（IT,スポーツ,家電,映画など）のWEBメディアごとにフォルダに記事がテキストファイルで保存されている\n",
    "    \n",
    "以下、ファイルを読み込んで、必要な部分を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\", \"ldcc-20140209.tar.gz\")\n",
    "# ダウンロードした圧縮ファイルのパスを設定\n",
    "#tgz_fname = \"ldcc-20140209.tar.gz\" \n",
    "# 2つをニュースメディアのジャンルを選定\n",
    "mydata = '/export/livedoor' \n",
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "\"\"\"\n",
    "def read_url(f):\n",
    "    url = next(f)\n",
    "    return url[:-1]\n",
    "\n",
    "def read_date(f):\n",
    "    date = next(f)\n",
    "    date = remove_brackets(date.encode().decode('utf-8'))\n",
    "    return date[:-1]\n",
    "\"\"\"\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/it-life-hack']\n",
    "#target_genre = [\"dokujo-tsushin\", \"it-life-hack\"] \n",
    "directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/peachy']\n",
    "target_genre = [\"dokujo-tsushin\", \"peachy\"] \n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "        #if os.path.isfile(f):\n",
    "        #    print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHvN-a5eBOAz"
   },
   "source": [
    "pandasでデータを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1661699114833,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "ks8ElHxNBLkJ",
    "outputId": "ec1e362f-f5e8-4e46-a292-61b26861585d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1712, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>まだ間に合う、癒しと大人のクリスマ</td>\n",
       "      <td>いよいよ、本格的なクリスマスシーズンに突入しました。イルミネーションスポットに赴き、美しい夜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>終了しました食べてキレイに！美フードバトル美禅食を10名様にプレゼン</td>\n",
       "      <td>写真一覧8件仕事に恋に、てんてこまいな女子の毎日。キレイへの近道は食生活を改善することとはわ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>遊びで終わる女の特徴結婚前に二人の相性を再チェックなど恋愛週間ランキン</td>\n",
       "      <td>Peachyでも大人気の恋愛をテーマにした記事の週間ランキングです！2012年8月16日8月...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>オトナ女子のリアルな悩み2年前に勤めていた会社の人を今頃になって好き</td>\n",
       "      <td>タイミングは恋するうえで重要な要素である。もし、好きな人が出来たとしても、タイミングが悪けれ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>超簡単な二の腕ほっそり体操ティッシュ箱で骨盤を鍛えるお気に入り登録記事週間ランキン</td>\n",
       "      <td>Peachyアプリを利用している皆さま、アプリのお気に入り機能は使っていますか？お気に入りと...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>大震災をきっかけに考える。在宅勤務はアリかナシか</td>\n",
       "      <td>東日本大震災の影響で、電力不足が懸念される今年の夏。サマータイムの導入やお盆休みの分散化など...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>伝説の4人に日本中が熱狂！SATC2ジャパンプレミ</td>\n",
       "      <td>全世界興収4億ドルを記録した映画の続編セックスアンドザシティ2がいよいよ6月4日より全国ロー...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>節電しながらムーディーな照明で夜を楽しもう</td>\n",
       "      <td>東日本大震災直後は節電で夜の街が暗くなり、電気のありがたみを実感したものだった。あれからもう...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>JYJユチョン主演のスリリングな恋愛ドラマミスリプリーレンタル開始決</td>\n",
       "      <td>愛と嘘の心理戦が観るものを惹きつけるドラマミスリプリー。韓国では初回放送から視聴率1位を獲得...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>向井理さんの今の時間帯だと言えないヒミ</td>\n",
       "      <td>昨年一大ブームを巻き起こしたドラマゲゲゲの女房で、人気を不動のものにした向井理さん。9日、ク...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          media_name  label                                      title  \\\n",
       "1279          peachy      1                          まだ間に合う、癒しと大人のクリスマ   \n",
       "1615          peachy      1         終了しました食べてキレイに！美フードバトル美禅食を10名様にプレゼン   \n",
       "1626          peachy      1        遊びで終わる女の特徴結婚前に二人の相性を再チェックなど恋愛週間ランキン   \n",
       "804   dokujo-tsushin      0         オトナ女子のリアルな悩み2年前に勤めていた会社の人を今頃になって好き   \n",
       "1643          peachy      1  超簡単な二の腕ほっそり体操ティッシュ箱で骨盤を鍛えるお気に入り登録記事週間ランキン   \n",
       "319   dokujo-tsushin      0                   大震災をきっかけに考える。在宅勤務はアリかナシか   \n",
       "899           peachy      1                  伝説の4人に日本中が熱狂！SATC2ジャパンプレミ   \n",
       "23    dokujo-tsushin      0                      節電しながらムーディーな照明で夜を楽しもう   \n",
       "1157          peachy      1         JYJユチョン主演のスリリングな恋愛ドラマミスリプリーレンタル開始決   \n",
       "1112          peachy      1                        向井理さんの今の時間帯だと言えないヒミ   \n",
       "\n",
       "                                               sentence  \n",
       "1279  いよいよ、本格的なクリスマスシーズンに突入しました。イルミネーションスポットに赴き、美しい夜...  \n",
       "1615  写真一覧8件仕事に恋に、てんてこまいな女子の毎日。キレイへの近道は食生活を改善することとはわ...  \n",
       "1626  Peachyでも大人気の恋愛をテーマにした記事の週間ランキングです！2012年8月16日8月...  \n",
       "804   タイミングは恋するうえで重要な要素である。もし、好きな人が出来たとしても、タイミングが悪けれ...  \n",
       "1643  Peachyアプリを利用している皆さま、アプリのお気に入り機能は使っていますか？お気に入りと...  \n",
       "319   東日本大震災の影響で、電力不足が懸念される今年の夏。サマータイムの導入やお盆休みの分散化など...  \n",
       "899   全世界興収4億ドルを記録した映画の続編セックスアンドザシティ2がいよいよ6月4日より全国ロー...  \n",
       "23    東日本大震災直後は節電で夜の街が暗くなり、電気のありがたみを実感したものだった。あれからもう...  \n",
       "1157  愛と嘘の心理戦が観るものを惹きつけるドラマミスリプリー。韓国では初回放送から視聴率1位を獲得...  \n",
       "1112  昨年一大ブームを巻き起こしたドラマゲゲゲの女房で、人気を不動のものにした向井理さん。9日、ク...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "\n",
    "\n",
    "#df_ = pd.read_csv(\"summary_set_dokujo_it.tsv\", \n",
    "#                 delimiter='\\t', header=None, names=['summaries'])\n",
    "\n",
    "df_ = pd.read_csv(\"summary_set_dokujo_peachy.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['summaries'])\n",
    "\n",
    "# データの確認\n",
    "print(f'データサイズ： {df.shape}')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JN4ssEmBWda"
   },
   "source": [
    "//文章データをsentences、ラベルデータを labelsに保存、以降この2変数だけを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df.media_name.values\n",
    "labels = df.label.values\n",
    "titles = df.title.values\n",
    "sentences = df.sentence.values\n",
    "summaries = df_.summaries.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "def make_wakati(sentence):\n",
    "  # MeCabで分かち書きを行う\n",
    "    sentence = tagger.parse(sentence)\n",
    "  # 半角全角英数字などは削除する\n",
    "#    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
    "  # 記号なども削除する\n",
    "#    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
    "  # スペース区切で形態素の配列に変換する\n",
    "    wakati = sentence.split(\" \")\n",
    "  # 空要素を削除する\n",
    "    wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'結婚'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge=make_wakati(sentences[2])\n",
    "hoge[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wakati_sentences = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    wakati_sentences.append(make_wakati(sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['両親', 'や', '親', '族']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge = []\n",
    "hoge.append(wakati_sentences[0][0])\n",
    "hoge += wakati_sentences[0][1]\n",
    "hoge += wakati_sentences[0][2]\n",
    "hoge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(wakati_sentences):\n",
    "    continue\n",
    "print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcount = 128\n",
    "\n",
    "h_sentences = []\n",
    "t_sentences = []\n",
    "\n",
    "# wcount moji me kara kesu\n",
    "\n",
    "for i in enumerate(wakati_sentences):\n",
    "    #h_sent = []\n",
    "    h_len = 0\n",
    "    hn = 0\n",
    "    #h_sent.append(wakati_sentences[i[0]][0])\n",
    "    h_len += len(wakati_sentences[i[0]][0])\n",
    "    while h_len < wcount:\n",
    "        try:\n",
    "            hn += 1\n",
    "            if wakati_sentences[i[0]][hn]:\n",
    "                #print(hn, wakati_sentences[i[0]][hn])\n",
    "                #h_sent.append(wakati_sentences[i[0]][hn])\n",
    "                h_len += len(wakati_sentences[i[0]][hn])\n",
    "        except IndexError:\n",
    "            break\n",
    "    h_sentences.append(sentences[i[0]][:hn])\n",
    "    \n",
    "    #t_sent = []\n",
    "    t_len = 0\n",
    "    tn = 2\n",
    "    #t_sent.append(wakati_sentences[i[0]][-2])\n",
    "    t_len += len(wakati_sentences[i[0]][-2])\n",
    "    while t_len < wcount:\n",
    "        try:\n",
    "            tn += 1\n",
    "            if wakati_sentences[i[0]][tn]:\n",
    "                #print(tn, wakati_sentences[i[0]][tn])\n",
    "                #t_sent.append(wakati_sentences[i[0]][tn])\n",
    "                t_len += len(wakati_sentences[i[0]][tn])\n",
    "        except IndexError:\n",
    "            break\n",
    "    t_sentences.append(sentences[i[0]][-tn:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'両親や親族が高齢なってくると、自分の人生を見つめ直さないといけないことがある。自分が独女の場合はなお更である。今回の相談者ミミさん女性38歳は母親が介護が必要になった'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsentences = np.array(h_sentences)\n",
    "tsentences = np.array(t_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssentences = np.array(df_.summaries.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ssentences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = []\n",
    "asentences = np.append(emp, copy.deepcopy(sentences))\n",
    "ksentences = np.append(emp, copy.deepcopy(sentences))\n",
    "kksentences = np.append(emp, copy.deepcopy(sentences))\n",
    "\n",
    "# wcount moji me kara kesu\n",
    "\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        asentences[i[0]] = sentences[i[0]][:wcount]\n",
    "\n",
    "# ushiro kara wcount moji toru\n",
    "\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        ksentences[i[0]] = sentences[i[0]][-wcount:]\n",
    "\n",
    "# ushiro kara wcount moji toru ichiban ketsu wa toranai\n",
    "\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        am = wcount+10\n",
    "        a = sentences[i[0]][-am:]\n",
    "        kksentences[i[0]] = a[:wcount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'と。絶えず自分が彼にとって何ができるかを考え、それを実行することに尽きると思う。しかしどんなに努力をしても、彼の心が離れてしまうこともある。そういう時は去る者は追わず。彼をつなぎ止めようとした努力は、次の恋に必ず役に立つと信じよう。オフィスエムツー佐枝せつ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksentences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlNaKoNRBhuo"
   },
   "source": [
    "# BERT Tokenizerを用いて単語分割・IDへ変換\n",
    "## Tokenizerの準備\n",
    "単語分割とIDへ変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ueumK1gF-D2"
   },
   "source": [
    "# テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1661699115434,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "9k0mj33mGD0I",
    "outputId": "9b3f3369-617c-4706-bbd7-7a9d1d0bb7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大単語数:  63\n",
      "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
     ]
    }
   ],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for sent in hsentences:\n",
    "    # Tokenizeで分割\n",
    "    h_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(h_token_words))\n",
    "for sent in tsentences:\n",
    "    # Tokenizeで分割\n",
    "    t_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(t_token_words))\n",
    "# 最大の値を確認\n",
    "print('最大単語数: ', max(max_len))\n",
    "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1661699115966,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "-xsginzEGHf5",
    "outputId": "6bf49efd-8a7d-452a-f16a-dd73d5f27b8b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  両親や親族が高齢なってくると、自分の人生を見つめ直さないといけないことがある。自分が独女の場合はなお更である。今回の相談者ミミさん女性38歳は母親が介護が必要になった\n",
      "Original:  話占いメール占いでは霊感鑑定はもちろん、タロットから運勢の流れを読み解き、また、夢分析から近未来を予測します。関連サイトnifty電話占いメール占い翔生先生プロフィー\n",
      "Token IDs: tensor([    9,  3652,    26, 13508,    12, 19860,    57,  9123,    20,     7,\n",
      "         1393,  4221,  1429, 15133,   442,  4569,    20, 19133,  1272,     8,\n",
      "         5144,  2596,   612,  2855,  3244, 13426,    27,     8, 16058,  5448,\n",
      "          147,   318,   318,   774,   577,  1300,   559,    11,  4180,    12,\n",
      "        12079,  3413,   344,     2,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n",
      "<class 'torch.Tensor'> tensor([0, 0, 0,  ..., 1, 1, 1])\n",
      "torch.Size([1712, 130])\n",
      "torch.Size([1712, 130])\n",
      "torch.Size([1712])\n",
      "1712\n"
     ]
    }
   ],
   "source": [
    "h_input_ids = []\n",
    "t_input_ids = []\n",
    "a_input_ids = []\n",
    "k_input_ids = []\n",
    "kk_input_ids = []\n",
    "s_input_ids = []\n",
    "h_attention_masks = []\n",
    "t_attention_masks = []\n",
    "a_attention_masks = []\n",
    "k_attention_masks = []\n",
    "kk_attention_masks = []\n",
    "s_attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for sent in hsentences:\n",
    "    hencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    h_input_ids.append(hencoded_dict['input_ids'])\n",
    "    h_attention_masks.append(hencoded_dict['attention_mask'])\n",
    "    \n",
    "for sent in tsentences:\n",
    "    tencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    t_input_ids.append(tencoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    t_attention_masks.append(tencoded_dict['attention_mask'])\n",
    "    \n",
    "for sent in asentences:\n",
    "    aencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    a_input_ids.append(aencoded_dict['input_ids'])\n",
    "    a_attention_masks.append(aencoded_dict['attention_mask'])\n",
    "    \n",
    "for sent in ksentences:\n",
    "    kencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    k_input_ids.append(kencoded_dict['input_ids'])\n",
    "    k_attention_masks.append(kencoded_dict['attention_mask'])\n",
    "    \n",
    "for sent in kksentences:\n",
    "    kkencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    kk_input_ids.append(kkencoded_dict['input_ids'])\n",
    "    kk_attention_masks.append(kkencoded_dict['attention_mask'])\n",
    "    \n",
    "for summa in ssentences:\n",
    "    sencoded_dict = tokenizer.encode_plus(\n",
    "                        summa,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = 50,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # 単語IDを取得    \n",
    "    s_input_ids.append(sencoded_dict['input_ids'])\n",
    "    # Attention　maskの取得\n",
    "    s_attention_masks.append(sencoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "h_input_ids = torch.cat(h_input_ids, dim=0)\n",
    "t_input_ids = torch.cat(t_input_ids, dim=0)\n",
    "a_input_ids = torch.cat(a_input_ids, dim=0)\n",
    "k_input_ids = torch.cat(k_input_ids, dim=0)\n",
    "kk_input_ids = torch.cat(kk_input_ids, dim=0)\n",
    "s_input_ids = torch.cat(s_input_ids, dim=0)\n",
    "h_attention_masks = torch.cat(h_attention_masks, dim=0)\n",
    "t_attention_masks = torch.cat(t_attention_masks, dim=0)\n",
    "a_attention_masks = torch.cat(a_attention_masks, dim=0)\n",
    "k_attention_masks = torch.cat(k_attention_masks, dim=0)\n",
    "kk_attention_masks = torch.cat(kk_attention_masks, dim=0)\n",
    "s_attention_masks = torch.cat(s_attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', hsentences[0])\n",
    "print('Original: ', tsentences[0])\n",
    "print('Token IDs:', h_input_ids[0])\n",
    "print(type(labels), labels)\n",
    "print(torch.Tensor.size(h_input_ids))\n",
    "print(torch.Tensor.size(h_attention_masks))\n",
    "print(torch.Tensor.size(labels))\n",
    "print(hsentences.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    9,  3652,    26,  ...,     3,     3,     3],\n",
       "        [    9,  3911,    10,  ...,     3,     3,     3],\n",
       "        [    9,  1743, 26243,  ...,     3,     3,     3],\n",
       "        ...,\n",
       "        [    9,  1583,  3887,  ...,     3,     3,     3],\n",
       "        [  692, 10359,   693,  ...,     3,     3,     3],\n",
       "        [    9,  1583,  3887,  ...,     3,     3,     3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1661699115968,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "uX3Hz3YNGKhH",
    "outputId": "bcba9374-dc24-4067-f46c-fa3d6343511c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torchvision import transforms, datasets\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "# データセットクラスの作成\n",
    "# dataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "hdataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "tdataset = TensorDataset(t_input_ids, t_attention_masks, labels)\n",
    "adataset = TensorDataset(a_input_ids, a_attention_masks, labels)\n",
    "kdataset = TensorDataset(k_input_ids, k_attention_masks, labels)\n",
    "kkdataset = TensorDataset(kk_input_ids, kk_attention_masks, labels)\n",
    "sdataset = TensorDataset(s_input_ids, s_attention_masks, labels)\n",
    "# dataset = CustomTensorDataset(tensors = (input_ids, labels), transform = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数:50\n",
      "検証データ数:1662\n"
     ]
    }
   ],
   "source": [
    "# 80%地点のIDを取得\n",
    "num_dataset = len(hdataset)\n",
    "#train_size = int(0.1 * num_dataset)\n",
    "#val_size = num_dataset - train_size\n",
    "\n",
    "train_size = 50\n",
    "val_size = len(hdataset) - train_size\n",
    "\n",
    "# データセhttp://localhost:8888/notebooks/bert-zuco/augmentation/BERTclassification-mydata-local-augmentation-aug.ipynb#ットを分割\n",
    "h_train_dataset, h_val_dataset = random_split(hdataset, [train_size, val_size])\n",
    "t_train_dataset, t_val_dataset = random_split(tdataset, [train_size, val_size])\n",
    "a_train_dataset, a_val_dataset = random_split(adataset, [train_size, val_size])\n",
    "k_train_dataset, k_val_dataset = random_split(kdataset, [train_size, val_size])\n",
    "kk_train_dataset, kk_val_dataset = random_split(kkdataset, [train_size, val_size])\n",
    "s_train_dataset, s_val_dataset = random_split(sdataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数:{}'.format(train_size))\n",
    "print('検証データ数:{}'.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "#batch_size = train_size\n",
    "batch_size = 50\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    synreplace(1),\n",
    "    randinsert(3),\n",
    "    randdelete(0.15), \n",
    "    randswap(2)\n",
    "])\n",
    "\n",
    "\n",
    "class MySubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xa, mask, label = self.dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            xa = self.transform(xa)\n",
    "        return xa, mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "indices = np.random.choice(num_dataset, num_dataset, replace=False)\n",
    "\n",
    "h_train_dataset = MySubset(hdataset, indices[:train_size], data_transform)\n",
    "h_val_dataset = MySubset(hdataset, indices[train_size:])\n",
    "t_train_dataset = MySubset(tdataset, indices[:train_size], data_transform)\n",
    "t_val_dataset = MySubset(tdataset, indices[train_size:])\n",
    "a_train_dataset = MySubset(adataset, indices[:train_size], data_transform)\n",
    "a_val_dataset = MySubset(adataset, indices[train_size:])\n",
    "k_train_dataset = MySubset(kdataset, indices[:train_size], data_transform)\n",
    "k_val_dataset = MySubset(kdataset, indices[train_size:])\n",
    "kk_train_dataset = MySubset(kkdataset, indices[:train_size], data_transform)\n",
    "kk_val_dataset = MySubset(kkdataset, indices[train_size:])\n",
    "s_train_dataset = MySubset(sdataset, indices[:train_size], data_transform)\n",
    "s_val_dataset = MySubset(sdataset, indices[train_size:])\n",
    "\n",
    "\n",
    "# 訓練データローダー\n",
    "h_train_dataloader = DataLoader(\n",
    "            h_train_dataset,  \n",
    "            sampler = RandomSampler(h_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "t_train_dataloader = DataLoader(\n",
    "            t_train_dataset,\n",
    "            sampler = RandomSampler(t_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "a_train_dataloader = DataLoader(\n",
    "            a_train_dataset,\n",
    "            sampler = RandomSampler(a_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "k_train_dataloader = DataLoader(\n",
    "            k_train_dataset,\n",
    "            sampler = RandomSampler(k_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "kk_train_dataloader = DataLoader(\n",
    "            kk_train_dataset,\n",
    "            sampler = RandomSampler(kk_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "s_train_dataloader = DataLoader(\n",
    "            s_train_dataset,\n",
    "            sampler = RandomSampler(s_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "\n",
    "\n",
    "# 検証データローダー\n",
    "h_validation_dataloader = DataLoader(\n",
    "            h_val_dataset, \n",
    "            sampler = SequentialSampler(h_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "t_validation_dataloader = DataLoader(\n",
    "            t_val_dataset, \n",
    "            sampler = SequentialSampler(t_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "a_validation_dataloader = DataLoader(\n",
    "            a_val_dataset, \n",
    "            sampler = SequentialSampler(a_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "k_validation_dataloader = DataLoader(\n",
    "            k_val_dataset, \n",
    "            sampler = SequentialSampler(k_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "kk_validation_dataloader = DataLoader(\n",
    "            kk_val_dataset, \n",
    "            sampler = SequentialSampler(kk_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "s_validation_dataloader = DataLoader(\n",
    "            s_val_dataset, \n",
    "            sampler = SequentialSampler(s_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9929328cf8d246d2b5be77a5fca18c0f",
      "7ce3a9778e6841e38f6bb2c3d8cfe9b8",
      "8988d5fad2d14b9b97cd311e99093641",
      "e72ccacac3434f939cd0e4adfb3bcc4d",
      "a9503913e9204c7994b76af2f3fd7d3a",
      "105e552bd7bd468f976e099cbe7c74cf",
      "fe1020e5f4eb483fa3fce57764a2508c",
      "9bb08df9e5004f5da8678c2fd10c8eb2",
      "887ca9f3ec9247c4b402bc72745aad0d",
      "50d37681841a449094298dcb52ff9059",
      "9f37d02a0ba944dc9633a68d71891f87",
      "a93d3d99fab445ea80248bd9ae7b0d60",
      "fa68d1e07ae94cd2824d767335a63c64",
      "f69e8de282434b9aa8a457a73593d080",
      "1ed1c48157da42b7bc8719879f3c13c8",
      "7093eae4a1e94e7fbc341564be6a727c",
      "e13d9164a1a6418b87f8fc9f2f5d10eb",
      "c7b849cdaf324e108283b9930d31ec7e",
      "a6e9829602e047f5ab93e3dfb66195cb",
      "baa09b17fcba4d8593e8155907a72c31",
      "7481c5bc470c42cf8ef6d38b69c4ce8a",
      "240f4e1960d44c189adf177c9eb4a17e"
     ]
    },
    "executionInfo": {
     "elapsed": 28456,
     "status": "ok",
     "timestamp": 1661699144410,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "tXUhEdWTGPRs",
    "outputId": "f525692a-ffa0-49cf-a54c-0f91707721b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 03:37:53.673152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-20 03:37:53.797169: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-20 03:37:54.223133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-20 03:37:54.223178: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-20 03:37:54.223183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinaryなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "# モデルをGPUへ転送\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1661699144412,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "cq-TvSWHJrQS",
    "outputId": "4a256f4d-c7cc-4ee4-98ae-cc2ca7b6d597"
   },
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 訓練パートの定義\n",
    "def h_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    h_train_loss = 0\n",
    "    for batch in h_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        h_train_loss += loss.item()\n",
    "    return h_train_loss\n",
    "\n",
    "\n",
    "# テストパートの定義\n",
    "def h_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    h_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in h_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            h_val_loss += loss.item()\n",
    "    return h_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    t_train_loss = 0\n",
    "    for batch in t_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        t_train_loss += loss.item()\n",
    "    return t_train_loss\n",
    "\n",
    "def t_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    t_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in t_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            t_val_loss += loss.item()\n",
    "    return t_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    a_train_loss = 0\n",
    "    for batch in a_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        a_train_loss += loss.item()\n",
    "    return a_train_loss\n",
    "\n",
    "def a_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    a_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in a_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            a_val_loss += loss.item()\n",
    "    return a_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    k_train_loss = 0\n",
    "    for batch in k_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        k_train_loss += loss.item()\n",
    "    return k_train_loss\n",
    "\n",
    "def k_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    k_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in k_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            k_val_loss += loss.item()\n",
    "    return k_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kk_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    kk_train_loss = 0\n",
    "    for batch in kk_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        kk_train_loss += loss.item()\n",
    "    return kk_train_loss\n",
    "\n",
    "def kk_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    kk_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in kk_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            kk_val_loss += loss.item()\n",
    "    return kk_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    s_train_loss = 0\n",
    "    for batch in s_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        s_train_loss += loss.item()\n",
    "    return s_train_loss\n",
    "\n",
    "def s_validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    s_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in s_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            s_val_loss += loss.item()\n",
    "    return s_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iPwWkV3HJtaG"
   },
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "max_epoch = 50\n",
    "t_train_loss_ = []\n",
    "t_test_loss_ = []\n",
    "h_train_loss_ = []\n",
    "h_test_loss_ = []\n",
    "a_train_loss_ = []\n",
    "a_test_loss_ = []\n",
    "k_train_loss_ = []\n",
    "k_test_loss_ = []\n",
    "kk_train_loss_ = []\n",
    "kk_test_loss_ = []\n",
    "s_train_loss_ = []\n",
    "s_test_loss_ = []\n",
    "\n",
    "\n",
    "h_train_loss = 0\n",
    "t_train_loss = 0\n",
    "a_train_loss = 0\n",
    "k_train_loss = 0\n",
    "kk_train_loss = 0\n",
    "s_train_loss = 0\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    h_train_ = h_train(model)\n",
    "    h_test_ = h_train(model)\n",
    "    h_train_loss_.append(h_train_)\n",
    "    h_test_loss_.append(h_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_input_mask.size(), b_input_ids.size(), labels.size()\n",
    "# outputs = self.model(torch.unsqueeze(token_tensor, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    9,     3,  7144,  ...,     3,     3,     3],\n",
       "         [    9,  1055,     9,  ...,     3,     3,     3],\n",
       "         [ 2732,     9,     9,  ...,     3,     3,     3],\n",
       "         ...,\n",
       "         [ 1042,     9,     9,  ...,     3,     3,     3],\n",
       "         [    9, 22213,    27,  ...,     3,     3,     3],\n",
       "         [ 9099,    22,  2090,  ...,     3,     3,     3]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 0])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoge = h_train_dataloader.__iter__()\n",
    "hoge.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train() # 訓練モードで実行\n",
    "h_test_accuracy = []\n",
    "hoge = 0\n",
    "hogehoge = 0\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    h_train_ = h_train(model)\n",
    "    h_test_ = h_train(model)\n",
    "    h_train_loss_.append(h_train_)\n",
    "    h_test_loss_.append(h_test_)\n",
    "\n",
    "for batch in h_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    h_loss = outputs.loss\n",
    "    h_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    h_train_loss += h_loss.item()\n",
    "\n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "# print(h_preds)\n",
    "\n",
    "for batch in h_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        h_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        h_test_accuracy.append((torch.argmax(h_preds[0], 1) == b_labels).sum().item() / len(b_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    t_train_ = t_train(model)\n",
    "    t_test_ = t_train(model)\n",
    "    t_train_loss_.append(t_train_)\n",
    "    t_test_loss_.append(t_test_)\n",
    "\n",
    "model.train() # 訓練モードで実行\n",
    "t_test_accuracy = []\n",
    "\n",
    "for batch in t_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    t_loss = outputs.loss\n",
    "    t_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    t_train_loss += t_loss.item()\n",
    "    \n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in t_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        t_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        t_test_accuracy.append((torch.argmax(t_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    a_train_ = a_train(model)\n",
    "    a_test_ = a_train(model)\n",
    "    a_train_loss_.append(a_train_)\n",
    "    a_test_loss_.append(a_test_)\n",
    "\n",
    "model.train() # 訓練モードで実行\n",
    "a_test_accuracy = []\n",
    "\n",
    "for batch in a_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    a_loss = outputs.loss\n",
    "    a_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    a_train_loss += a_loss.item()\n",
    "    \n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in a_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        a_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        a_test_accuracy.append((torch.argmax(a_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    k_train_ = k_train(model)\n",
    "    k_test_ = k_train(model)\n",
    "    k_train_loss_.append(k_train_)\n",
    "    k_test_loss_.append(k_test_)\n",
    "\n",
    "model.train() # 訓練モードで実行\n",
    "k_test_accuracy = []\n",
    "\n",
    "for batch in a_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    k_loss = outputs.loss\n",
    "    k_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    k_train_loss += k_loss.item()\n",
    "    \n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in a_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        k_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        k_test_accuracy.append((torch.argmax(k_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    kk_train_ = kk_train(model)\n",
    "    kk_test_ = kk_train(model)\n",
    "    kk_train_loss_.append(kk_train_)\n",
    "    kk_test_loss_.append(kk_test_)\n",
    "\n",
    "model.train() # 訓練モードで実行\n",
    "kk_test_accuracy = []\n",
    "\n",
    "for batch in a_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    kk_loss = outputs.loss\n",
    "    kk_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    kk_train_loss += kk_loss.item()\n",
    "    \n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in a_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        kk_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        kk_test_accuracy.append((torch.argmax(kk_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    9,   729, 19104,  ...,     3,     3,     3],\n",
       "         [ 5498, 25629,     3,  ...,     3,     3,     3],\n",
       "         [  235,   141,     3,  ...,     3,     3,     3],\n",
       "         ...,\n",
       "         [    9,  7058,  3865,  ...,     3,     3,     3],\n",
       "         [    9,  1961,    12,  ...,     3,     3,     3],\n",
       "         [    9,     3, 22213,  ...,     3,     3,     3]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "         0, 1])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(s_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    s_train_ = s_train(model)\n",
    "    s_test_ = s_train(model)\n",
    "    s_train_loss_.append(s_train_)\n",
    "    s_test_loss_.append(s_test_)\n",
    "\n",
    "model.train() # 訓練モードで実行\n",
    "s_test_accuracy = []\n",
    "\n",
    "for batch in a_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    s_loss = outputs.loss\n",
    "    s_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    s_train_loss += s_loss.item()\n",
    "    \n",
    "model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in a_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        s_preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        s_test_accuracy.append((torch.argmax(s_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    sents.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[i])))\n",
    "\n",
    "#print(sents)\n",
    "sents = pd.DataFrame(sents)\n",
    "print(type(sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsentences = np.append(emp, copy.deepcopy(sentences))\n",
    "\n",
    "l_input_ids = []\n",
    "l_attention_masks = []\n",
    "\n",
    "for sent in lsentences:\n",
    "    aencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    l_input_ids.append(aencoded_dict['input_ids'])\n",
    "    l_attention_masks.append(aencoded_dict['attention_mask'])\n",
    "\n",
    "l_input_ids = torch.cat(l_input_ids, dim=0)\n",
    "l_attention_masks = torch.cat(l_attention_masks, dim=0)\n",
    "ldataset = TensorDataset(l_input_ids, kk_attention_masks, labels)\n",
    "l_train_dataset, l_val_dataset = random_split(ldataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type soroete X train test Y train test wo kaizan suru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test, y_train, y_test = train_test_split(\\n    sents, labels, test_size=0.95, random_state=42, shuffle=True\\n    )\\nprint(y_train)\\n\\n# x ga transformer id  y ga raberu\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sents, labels, test_size=0.95, random_state=42, shuffle=True\n",
    "    )\n",
    "print(y_train)\n",
    "\n",
    "# x ga transformer id  y ga raberu\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(type(y_train))\\nprint(type(l_train_dataset[0][2]))\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(type(y_train))\n",
    "print(type(l_train_dataset[0][2]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = l_train_dataset[:][0] \n",
    "Xtest = l_val_dataset[:][0]\n",
    "ytrain = l_train_dataset[:][2]\n",
    "ytest = l_val_dataset[:][2]\n",
    "\n",
    "X_train = Xtrain.to('cpu').detach().numpy().copy()\n",
    "X_test = Xtest.to('cpu').detach().numpy().copy()\n",
    "y_train = ytrain.to('cpu').detach().numpy().copy()\n",
    "y_test = ytest.to('cpu').detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's binary_logloss: 0.644788\tvalid_0's binary_logloss: 0.703826\n",
      "[10]\ttraining's binary_logloss: 0.610809\tvalid_0's binary_logloss: 0.710678\n",
      "[15]\ttraining's binary_logloss: 0.582111\tvalid_0's binary_logloss: 0.716618\n",
      "[20]\ttraining's binary_logloss: 0.556623\tvalid_0's binary_logloss: 0.721171\n",
      "[25]\ttraining's binary_logloss: 0.534078\tvalid_0's binary_logloss: 0.729729\n",
      "[30]\ttraining's binary_logloss: 0.511494\tvalid_0's binary_logloss: 0.733497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(max_depth=50, num_iterations=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(max_depth=50, num_iterations=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(max_depth=50, num_iterations=30)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lightgbm.LGBMClassifier(max_depth=50, num_iterations=30)\n",
    "eval_res = {}\n",
    "lgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test), (X_train, y_train)], verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "1662\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(len(y_pred))\n",
    "dnum = len(y_pred) % batch_size\n",
    "print(dnum)\n",
    "l_preds = y_pred[-dnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(l_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head:  0.5862745098039216\n",
      "tail:  0.645\n",
      "atama:  0.6685294117647059\n",
      "ketsu:  0.6484313725490196\n",
      "ketsu kestu:  0.6586274509803922\n",
      "summary:  0.5490196078431373\n",
      "LGBM:  0.49518652226233456\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_test)\n",
    "print('head: ', statistics.mean(h_test_accuracy))\n",
    "print('tail: ', statistics.mean(t_test_accuracy))\n",
    "print('atama: ', statistics.mean(a_test_accuracy))\n",
    "print('ketsu: ', statistics.mean(k_test_accuracy))\n",
    "print('ketsu kestu: ', statistics.mean(kk_test_accuracy))\n",
    "print('summary: ', statistics.mean(s_test_accuracy))\n",
    "print('LGBM: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_pred_label</th>\n",
       "      <th>t_pred_label</th>\n",
       "      <th>a_pred_label</th>\n",
       "      <th>k_pred_label</th>\n",
       "      <th>kk_pred_label</th>\n",
       "      <th>s_pred_label</th>\n",
       "      <th>l_pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    h_pred_label  t_pred_label  a_pred_label  k_pred_label  kk_pred_label  \\\n",
       "0              0             0             0             0              0   \n",
       "1              1             1             1             1              1   \n",
       "2              0             0             0             0              0   \n",
       "3              1             1             1             1              1   \n",
       "4              1             0             1             1              1   \n",
       "5              0             0             1             0              1   \n",
       "6              0             0             0             0              0   \n",
       "7              0             0             0             0              0   \n",
       "8              0             0             1             0              1   \n",
       "9              0             0             1             1              1   \n",
       "10             0             0             1             0              0   \n",
       "11             0             0             1             1              1   \n",
       "\n",
       "    s_pred_label  l_pred_label  true_label  \n",
       "0              0             0           0  \n",
       "1              0             1           1  \n",
       "2              0             1           0  \n",
       "3              0             0           1  \n",
       "4              1             0           1  \n",
       "5              0             1           1  \n",
       "6              0             1           0  \n",
       "7              0             0           0  \n",
       "8              0             0           1  \n",
       "9              0             0           0  \n",
       "10             0             1           0  \n",
       "11             0             0           0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pred_df = pd.DataFrame(np.argmax(h_preds[0].cpu().numpy(), axis=1), columns=['h_pred_label'])\n",
    "t_pred_df = pd.DataFrame(np.argmax(t_preds[0].cpu().numpy(), axis=1), columns=['t_pred_label'])\n",
    "a_pred_df = pd.DataFrame(np.argmax(a_preds[0].cpu().numpy(), axis=1), columns=['a_pred_label'])\n",
    "k_pred_df = pd.DataFrame(np.argmax(k_preds[0].cpu().numpy(), axis=1), columns=['k_pred_label'])\n",
    "kk_pred_df = pd.DataFrame(np.argmax(kk_preds[0].cpu().numpy(), axis=1), columns=['kk_pred_label'])\n",
    "s_pred_df = pd.DataFrame(np.argmax(s_preds[0].cpu().numpy(), axis=1), columns=['s_pred_label'])\n",
    "l_preds_df = pd.DataFrame(l_preds, columns=['l_pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([h_pred_df, t_pred_df, a_pred_df, k_pred_df, kk_pred_df, s_pred_df, l_preds_df, label_df], axis=1)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpreds = h_pred_df.values\n",
    "tpreds = t_pred_df.values\n",
    "apreds = a_pred_df.values\n",
    "kpreds = k_pred_df.values\n",
    "kkpreds = kk_pred_df.values\n",
    "spreds = s_pred_df.values\n",
    "lpreds = np.array(l_preds)\n",
    "preds = []\n",
    "pred = 0\n",
    "m = 7\n",
    "\n",
    "for i in range(len(hpreds)):\n",
    "    pred = hpreds[i]+tpreds[i]+apreds[i]+kpreds[i]+kkpreds[i]+spreds[i]+lpreds[i]\n",
    "    if pred/m < 0.5:\n",
    "        pred = 0\n",
    "    else:\n",
    "        pred = 1\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_label  true_label\n",
       "0            0           0\n",
       "1            1           1\n",
       "2            0           0\n",
       "3            1           1\n",
       "4            1           1\n",
       "5            0           1\n",
       "6            0           0\n",
       "7            0           0\n",
       "8            0           1\n",
       "9            0           0\n",
       "10           0           0\n",
       "11           0           0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df = pd.DataFrame(preds, columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "ensaccuracy_df = pd.concat([preds_df, label_df], axis=1)\n",
    "ensaccuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.33333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = 0\n",
    "ypnum = 0 #yosoku\n",
    "spnum = 0 #seikai\n",
    "pnum = 0\n",
    "rnum = 0\n",
    "for i in range(len(preds_df)):\n",
    "    if preds_df.values[i] == label_df.values[i]:\n",
    "        cor += 1\n",
    "    if preds_df.values[i] == 0:\n",
    "        ypnum += 1\n",
    "        if label_df.values[i] == 0:\n",
    "            pnum += 1\n",
    "    if label_df.values[i] == 0:\n",
    "        spnum += 1\n",
    "        if preds_df.values[i] == 0:\n",
    "            rnum += 1\n",
    "        \n",
    "100*cor/len(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43750000000000006"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tekigou\n",
    "tp = pnum/ypnum\n",
    "# saigen\n",
    "sp = rnum/spnum\n",
    "\n",
    "(tp*sp)/(tp+sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pdf):\n",
    "    cor = 0\n",
    "    for i in range(len(preds_df)):\n",
    "        if pdf[i] == label_df.values[i]:\n",
    "            cor += 1\n",
    "    acc = 100*cor/len(pdf)\n",
    "    return acc\n",
    "\n",
    "def fscore(pdf):\n",
    "    cor = 0\n",
    "    ypnum = 0 #yosoku\n",
    "    spnum = 0 #seikai\n",
    "    pnum = 0\n",
    "    rnum = 0\n",
    "    fone = 0\n",
    "    for i in range(len(preds_df)):\n",
    "        if pdf[i] == label_df.values[i]:\n",
    "            cor += 1\n",
    "        if pdf[i] == 0:\n",
    "            ypnum += 1\n",
    "            if label_df.values[i] == 0:\n",
    "                pnum += 1\n",
    "        if label_df.values[i] == 0:\n",
    "            spnum += 1\n",
    "            if pdf[i] == 0:\n",
    "                rnum += 1\n",
    "    # tekigou\n",
    "    tp = pnum/ypnum\n",
    "    # saigen\n",
    "    sp = rnum/spnum\n",
    "    # f1\n",
    "    fone = (tp*sp)/(tp+sp)\n",
    "    return fone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head 83.33333333333333 0.43750000000000006\n",
      "tail 75.0 0.4117647058823529\n",
      "atama 75.0 0.36363636363636365\n",
      "ketsu 66.66666666666667 0.35714285714285715\n",
      "ketsu-10 83.33333333333333 0.41666666666666663\n",
      "summary 66.66666666666667 0.3888888888888889\n",
      "lgbm 50.0 0.2857142857142857\n",
      "all 83.33333333333333 0.43750000000000006\n"
     ]
    }
   ],
   "source": [
    "print('head', accuracy(hpreds), fscore(hpreds))\n",
    "print('tail', accuracy(tpreds), fscore(tpreds))\n",
    "print('atama', accuracy(apreds), fscore(apreds))\n",
    "print('ketsu', accuracy(kpreds), fscore(kpreds))\n",
    "print('ketsu-10', accuracy(kkpreds), fscore(kkpreds))\n",
    "print('summary', accuracy(spreds), fscore(spreds))\n",
    "print('lgbm', accuracy(lpreds), fscore(lpreds))\n",
    "print('all', accuracy(preds_df.values), fscore(preds_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1661699237395,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "pHF_S3-tJx9i",
    "outputId": "763f4858-5255-4ddf-ade2-0b67dd0d5b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力:SequenceClassifierOutput(loss=None, logits=tensor([[ 2.4832, -2.6870],\n",
      "        [-0.9536,  1.5584],\n",
      "        [ 1.9074, -1.9481],\n",
      "        [-0.9536,  1.5584],\n",
      "        [-2.6089,  3.1219],\n",
      "        [ 3.1842, -3.5541],\n",
      "        [ 1.0505, -1.1218],\n",
      "        [ 3.0147, -3.5454],\n",
      "        [ 3.2111, -3.5479],\n",
      "        [ 2.7651, -2.9229],\n",
      "        [ 2.9217, -3.1821],\n",
      "        [ 2.3618, -2.3646]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の確認\n",
    "print(f'出力:{h_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1661699237396,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "5JCSY_YpJ0Qm",
    "outputId": "624497aa-500a-478b-c8fe-0727efee504a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 比較しやすい様にpd.dataframeへ整形\\nimport numpy as np\\n# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\\nlogits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\\n## np.argmaxで大き方の値を取得\\npred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\\nlabel_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\\naccuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\\naccuracy_df.head()\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 比較しやすい様にpd.dataframeへ整形\n",
    "import numpy as np\n",
    "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
    "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
    "## np.argmaxで大き方の値を取得\n",
    "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
    "accuracy_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorrect = 0\\ntest_accuracy = 0\\n\\np_list = []\\nl_list = []\\n\\np_list = pred_df.values.tolist()\\nl_list = label_df.values.tolist()\\n\\n#print(type(pred_df))\\n\\nfor i in range(len(b_labels)):\\n    if(p_list[i] == l_list[i]):\\n        correct += 1\\n\\ntest_accuracy = correct/len(b_labels)\\n\\nprint(test_accuracy)\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "correct = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "p_list = []\n",
    "l_list = []\n",
    "\n",
    "p_list = pred_df.values.tolist()\n",
    "l_list = label_df.values.tolist()\n",
    "\n",
    "#print(type(pred_df))\n",
    "\n",
    "for i in range(len(b_labels)):\n",
    "    if(p_list[i] == l_list[i]):\n",
    "        correct += 1\n",
    "\n",
    "test_accuracy = correct/len(b_labels)\n",
    "\n",
    "print(test_accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_test_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(h_test_loss_)), h_test_loss_, label=\"Head\")\n",
    "plt.plot(range(len(t_test_loss_)), t_test_loss_, label=\"Tail\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()  # ラベルがあるときは、きちんとplt.show()を呼び出すこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERTclassification.ipynb",
   "provenance": [
    {
     "file_id": "1mxMTVW123hMPhZLg9UjVEhkL_vrFvMp7",
     "timestamp": 1659890794413
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08a0764a15bb4b45ab9bfdbe3a02c318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b407dd3170f4f55be7f8708c59d262b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5616789e354d45699ea2040757dbd5c3",
       "IPY_MODEL_d6bc8aac6ca74bff92bba66f17c20b00",
       "IPY_MODEL_96fb1e06ef4349b5b6a071be230a711c"
      ],
      "layout": "IPY_MODEL_8d05e54e5fc644d2a3c974758c5e439c"
     }
    },
    "105e552bd7bd468f976e099cbe7c74cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11cc64e4ce0843ae88a651762d68b844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1aff4434a10549e387f749140d4721f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ed1c48157da42b7bc8719879f3c13c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7481c5bc470c42cf8ef6d38b69c4ce8a",
      "placeholder": "​",
      "style": "IPY_MODEL_240f4e1960d44c189adf177c9eb4a17e",
      "value": " 424M/424M [00:15&lt;00:00, 54.9MB/s]"
     }
    },
    "240f4e1960d44c189adf177c9eb4a17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dc2139703bb4448969390f2a91e00f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994b8f69c284d758c5f04deeb3fcca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "423c0b6849204bbc96c7b039633373f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4535f833bfac4540a8add9686f623b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9279616c547b47de92a436ebb026fd79",
      "max": 153,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3910389daf34e31af5f33ef7d539625",
      "value": 153
     }
    },
    "45555846fc9746af9a06d76c6c9aee1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46351ebb1bfd41b5b9fbc4de40e218e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50d37681841a449094298dcb52ff9059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5616789e354d45699ea2040757dbd5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a20acb0a8fc4320af5a849c9d780649",
      "placeholder": "​",
      "style": "IPY_MODEL_45555846fc9746af9a06d76c6c9aee1b",
      "value": "Downloading spiece.model: 100%"
     }
    },
    "705cf2ba17614d51853eeb9dfc74d540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3994b8f69c284d758c5f04deeb3fcca1",
      "max": 259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08a0764a15bb4b45ab9bfdbe3a02c318",
      "value": 259
     }
    },
    "7093eae4a1e94e7fbc341564be6a727c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fb8df2799443d996d165878dc526a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9f368ede2d24e3095242e9a3cf8c545",
       "IPY_MODEL_4535f833bfac4540a8add9686f623b54",
       "IPY_MODEL_7803695cfa5742bf85208ee04193acb0"
      ],
      "layout": "IPY_MODEL_423c0b6849204bbc96c7b039633373f9"
     }
    },
    "7481c5bc470c42cf8ef6d38b69c4ce8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7803695cfa5742bf85208ee04193acb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d808ec79b0dd465a82077ca7f2c8feb6",
      "placeholder": "​",
      "style": "IPY_MODEL_d2a46f9221b14f86a3330510812f258e",
      "value": " 153/153 [00:00&lt;00:00, 4.82kB/s]"
     }
    },
    "7ce3a9778e6841e38f6bb2c3d8cfe9b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_105e552bd7bd468f976e099cbe7c74cf",
      "placeholder": "​",
      "style": "IPY_MODEL_fe1020e5f4eb483fa3fce57764a2508c",
      "value": "Downloading config.json: 100%"
     }
    },
    "83cf06c42be34c068dbbf6fcc5cfd6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f629f372d73b44efb31e8d7c5a45d4cd",
      "placeholder": "​",
      "style": "IPY_MODEL_93c25b4c96e64fecbb7f569527e50722",
      "value": " 259/259 [00:00&lt;00:00, 8.26kB/s]"
     }
    },
    "887ca9f3ec9247c4b402bc72745aad0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8988d5fad2d14b9b97cd311e99093641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bb08df9e5004f5da8678c2fd10c8eb2",
      "max": 479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_887ca9f3ec9247c4b402bc72745aad0d",
      "value": 479
     }
    },
    "8d05e54e5fc644d2a3c974758c5e439c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9279616c547b47de92a436ebb026fd79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "937dd0c1d06e4d69824b7be991cc52f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c25b4c96e64fecbb7f569527e50722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96fb1e06ef4349b5b6a071be230a711c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd4beed83d947b9a5eec5918dcd2319",
      "placeholder": "​",
      "style": "IPY_MODEL_1aff4434a10549e387f749140d4721f4",
      "value": " 787k/787k [00:00&lt;00:00, 11.4MB/s]"
     }
    },
    "9929328cf8d246d2b5be77a5fca18c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ce3a9778e6841e38f6bb2c3d8cfe9b8",
       "IPY_MODEL_8988d5fad2d14b9b97cd311e99093641",
       "IPY_MODEL_e72ccacac3434f939cd0e4adfb3bcc4d"
      ],
      "layout": "IPY_MODEL_a9503913e9204c7994b76af2f3fd7d3a"
     }
    },
    "9a20acb0a8fc4320af5a849c9d780649": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9b67b9ebf94a13a95e759a696c884f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bb08df9e5004f5da8678c2fd10c8eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f37d02a0ba944dc9633a68d71891f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0880f15772d4156a9eb94d6314c2d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e9829602e047f5ab93e3dfb66195cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93d3d99fab445ea80248bd9ae7b0d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa68d1e07ae94cd2824d767335a63c64",
       "IPY_MODEL_f69e8de282434b9aa8a457a73593d080",
       "IPY_MODEL_1ed1c48157da42b7bc8719879f3c13c8"
      ],
      "layout": "IPY_MODEL_7093eae4a1e94e7fbc341564be6a727c"
     }
    },
    "a9503913e9204c7994b76af2f3fd7d3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3910389daf34e31af5f33ef7d539625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baa09b17fcba4d8593e8155907a72c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7b849cdaf324e108283b9930d31ec7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f368ede2d24e3095242e9a3cf8c545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_937dd0c1d06e4d69824b7be991cc52f0",
      "placeholder": "​",
      "style": "IPY_MODEL_11cc64e4ce0843ae88a651762d68b844",
      "value": "Downloading special_tokens_map.json: 100%"
     }
    },
    "cfd1b9e85db447fbaf01f66f6f0f6429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dc2139703bb4448969390f2a91e00f6",
      "placeholder": "​",
      "style": "IPY_MODEL_46351ebb1bfd41b5b9fbc4de40e218e3",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "d2a46f9221b14f86a3330510812f258e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d337eb6795e241389d9b35805a59fc22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6bc8aac6ca74bff92bba66f17c20b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0880f15772d4156a9eb94d6314c2d9e",
      "max": 805634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d337eb6795e241389d9b35805a59fc22",
      "value": 805634
     }
    },
    "d808ec79b0dd465a82077ca7f2c8feb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd6aadfe79224713b5a47dd108ff71b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfd1b9e85db447fbaf01f66f6f0f6429",
       "IPY_MODEL_705cf2ba17614d51853eeb9dfc74d540",
       "IPY_MODEL_83cf06c42be34c068dbbf6fcc5cfd6d5"
      ],
      "layout": "IPY_MODEL_9a9b67b9ebf94a13a95e759a696c884f"
     }
    },
    "e13d9164a1a6418b87f8fc9f2f5d10eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e72ccacac3434f939cd0e4adfb3bcc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50d37681841a449094298dcb52ff9059",
      "placeholder": "​",
      "style": "IPY_MODEL_9f37d02a0ba944dc9633a68d71891f87",
      "value": " 479/479 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "efd4beed83d947b9a5eec5918dcd2319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f629f372d73b44efb31e8d7c5a45d4cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69e8de282434b9aa8a457a73593d080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6e9829602e047f5ab93e3dfb66195cb",
      "max": 445021143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baa09b17fcba4d8593e8155907a72c31",
      "value": 445021143
     }
    },
    "fa68d1e07ae94cd2824d767335a63c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e13d9164a1a6418b87f8fc9f2f5d10eb",
      "placeholder": "​",
      "style": "IPY_MODEL_c7b849cdaf324e108283b9930d31ec7e",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "fe1020e5f4eb483fa3fce57764a2508c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
