{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wcOk2ZzAAQr"
   },
   "source": [
    "# Hugging Face Library 'Transformer'およびT5Tokenizerのダウンロード\n",
    "\n",
    "参考( https://qiita.com/takubb/items/fd972f0ac3dba909c293 )これを基に改造し、最新のGoogle Colaboratoryで動作するようにした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_learn: 50  max_epoch: 1  num_of_batch: 64  articletype: dokujo_it\n",
      "l:50_e:1_b:64_t:rids_r:3_i:3_d:0.08_s:2_a:dokujo_it\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "\n",
    "parser = argparse.ArgumentParser(description='liBERTy testbed')\n",
    "#tp = lambda x:list(map(str, x.split(',')))\n",
    "parser.add_argument('-l', '--num_of_learn', type=int, default=100,\n",
    "    help='number (default 100) of learn, which determins the rate of dataset for the use of learning.')\n",
    "parser.add_argument('-v', '--num_of_validation', type=int, default=200,\n",
    "    help='number of validation to shorten the validation time.')\n",
    "parser.add_argument('-e', '--max_epoch', type=int, default=20, \n",
    "    help='number (default 20) of epoch to be executed for learning loop')\n",
    "parser.add_argument('-b', '--batch_size', type=int, default=64, \n",
    "    help='size (defaualt 64) of batch for learning process')\n",
    "parser.add_argument('-a', '--article_type', type=int, default=0, choices=[0,1], \n",
    "    help='article type (0: dokujo_it=default, 1:dokujo_peachy')\n",
    "parser.add_argument('-t', '--transformflags', default = 'n', #default='rids', \n",
    "    help='NLP-JP transformer (default n) r:synreplace i:randinsert d:randdelete s:randswap n:none')\n",
    "parser.add_argument('-r', '--synreplace_rate', type=int, default=3, \n",
    "    help='rate (default 3) of synreplace_rate par sentence as int for transformers.')\n",
    "parser.add_argument('-i', '--randinsert_rate', type=int, default=3, \n",
    "    help='rate (default 3) of randinsert of dataset par sentence as int for transformers.')\n",
    "parser.add_argument('-d', '--randdelete_rate', type=float, default=0.08, \n",
    "    help='probability (default 0.08) of lranddelete in a sentence as float of dataset for transformers.')\n",
    "parser.add_argument('-s', '--randswap_rate', type=int, default=2, \n",
    "    help='rate (default 2) of randswap of dataset per sentence as int for transformers.')\n",
    "parser.add_argument('-f', '--jupyter', default='CMD', \n",
    "    help='executed from jupyter')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.jupyter == 'CMD':\n",
    "    numof_learn = args.num_of_learn\n",
    "    numof_validation = args.num_of_validation\n",
    "    max_epoch = args.max_epoch\n",
    "    batch_size = args.batch_size\n",
    "    transformflags = args.transformflags\n",
    "    synreplace_rate = args.synreplace_rate\n",
    "    randinsert_rate = args.randinsert_rate\n",
    "    randdelete_rate = args.randdelete_rate\n",
    "    randswap_rate = args.randswap_rate\n",
    "    articletype = args.article_type\n",
    "else:\n",
    "    numof_learn = 100\n",
    "    numof_validation = 200\n",
    "    max_epoch = 20\n",
    "    batch_size = 64\n",
    "    transformflags = 'n' #'rids'\n",
    "    synreplace_rate = 3\n",
    "    randinsert_rate = 3\n",
    "    randdelete_rate = 0.08\n",
    "    randswap_rate = 2\n",
    "    articletype = 0\n",
    "\n",
    "articlelabel = ['dokujo_it', 'dokujo_peachy']\n",
    "print(\"num_of_learn:\",numof_learn,\" max_epoch:\", max_epoch,\" num_of_batch:\", batch_size,\n",
    "      \" articletype:\", articlelabel[articletype])\n",
    "filestr = \"l:\"+str(numof_learn)+\"_e:\"+str(max_epoch)+\"_b:\"+str(batch_size)+\"_t:\"+transformflags+\\\n",
    "    \"_r:\"+str(synreplace_rate)+'_i:'+str(randinsert_rate)+'_d:'+str(randdelete_rate)+'_s:'+str(randswap_rate)+\\\n",
    "    \"_a:\"+articlelabel[articletype]\n",
    "print(filestr)\n",
    "transformflags = list(transformflags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0b407dd3170f4f55be7f8708c59d262b",
      "5616789e354d45699ea2040757dbd5c3",
      "d6bc8aac6ca74bff92bba66f17c20b00",
      "96fb1e06ef4349b5b6a071be230a711c",
      "8d05e54e5fc644d2a3c974758c5e439c",
      "9a20acb0a8fc4320af5a849c9d780649",
      "45555846fc9746af9a06d76c6c9aee1b",
      "a0880f15772d4156a9eb94d6314c2d9e",
      "d337eb6795e241389d9b35805a59fc22",
      "efd4beed83d947b9a5eec5918dcd2319",
      "1aff4434a10549e387f749140d4721f4",
      "73fb8df2799443d996d165878dc526a8",
      "c9f368ede2d24e3095242e9a3cf8c545",
      "4535f833bfac4540a8add9686f623b54",
      "7803695cfa5742bf85208ee04193acb0",
      "423c0b6849204bbc96c7b039633373f9",
      "937dd0c1d06e4d69824b7be991cc52f0",
      "11cc64e4ce0843ae88a651762d68b844",
      "9279616c547b47de92a436ebb026fd79",
      "b3910389daf34e31af5f33ef7d539625",
      "d808ec79b0dd465a82077ca7f2c8feb6",
      "d2a46f9221b14f86a3330510812f258e",
      "dd6aadfe79224713b5a47dd108ff71b9",
      "cfd1b9e85db447fbaf01f66f6f0f6429",
      "705cf2ba17614d51853eeb9dfc74d540",
      "83cf06c42be34c068dbbf6fcc5cfd6d5",
      "9a9b67b9ebf94a13a95e759a696c884f",
      "2dc2139703bb4448969390f2a91e00f6",
      "46351ebb1bfd41b5b9fbc4de40e218e3",
      "3994b8f69c284d758c5f04deeb3fcca1",
      "08a0764a15bb4b45ab9bfdbe3a02c318",
      "f629f372d73b44efb31e8d7c5a45d4cd",
      "93c25b4c96e64fecbb7f569527e50722"
     ]
    },
    "executionInfo": {
     "elapsed": 30796,
     "status": "ok",
     "timestamp": 1661865111605,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "DJ__bXJq_06p",
    "outputId": "b2d9fbba-45cc-4348-fadf-7b15798ffd4b"
   },
   "outputs": [],
   "source": [
    "#!export CUDA_LAUNCH_BLOCKING=1\n",
    "# !pip install torch\n",
    "#!pip install torchvision\n",
    "#!pip install transformers\n",
    "#!apt install swig\n",
    "#!pip install sentencepiece\n",
    "#!pip install mecab-python3\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # pytorchを同期実行させる\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='TRUE' # ライブラリ重複を無視\n",
    "import gzip\n",
    "import shutil\n",
    "import random\n",
    "from math import ceil\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import torchvision\n",
    "import statistics\n",
    "import numpy as np\n",
    "import statistics\n",
    "import MeCab\n",
    "import copy\n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpCa2h0oAU51"
   },
   "source": [
    "# PyTorchとGPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5548,
     "status": "ok",
     "timestamp": 1661865117146,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "hLV4lS8CAWCZ",
    "outputId": "6fa5cea1-0ec6-4aa3-82d5-53328e8b1c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_fix_seed(seed=24):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation kansuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "robertamodel = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synreplace - replace kasho kosuu\n",
    "# randinsert - tasu kotoba no kazu\n",
    "# randdelete - delete kakuritsu\n",
    "# randswap - swap kaisuu\n",
    "\n",
    "class synreplace(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        # textlist: honbun no list\n",
    "        if len(torch.where(textlist == 3)[0]):\n",
    "            textlen = torch.where(textlist == 3)[0][0]\n",
    "        else:\n",
    "            textlen = len(textlist)\n",
    "        for n in range(self.num):\n",
    "            # chikan shiro\n",
    "            masked_idx = random.randint(2, textlen-1)\n",
    "            textlist[masked_idx] = 6\n",
    "            # convert to tensor\n",
    "            token_tensor = torch.tensor(textlist)\n",
    "            # get the top 10 predictions of the masked token\n",
    "            self.model = robertamodel.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(torch.unsqueeze(token_tensor, 0))\n",
    "                predictions = outputs[0][0, masked_idx].topk(1)\n",
    "            for i, index_t in enumerate(predictions.indices):\n",
    "                index = index_t.item()\n",
    "            textlist[masked_idx] = index\n",
    "        return textlist\n",
    "\n",
    "class randinsert(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        for n in range(self.num):\n",
    "            insword = textlist[random.randint(1,len(textlist)-1)]\n",
    "            i = random.randint(1,len(textlist)-1)\n",
    "#            print('len: ', len(textlist))\n",
    "#            print(i)\n",
    "            while textlist[i] == 3 or  textlist[i] == 9:\n",
    "                i = random.randint(1,len(textlist)-1)\n",
    "#                print(i)\n",
    "            textlist = torch.cat([textlist[0:i], torch.tensor([insword]), textlist[i:-1]])\n",
    "        return textlist\n",
    "\n",
    "class randdelete(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "#        print(textlist.shape)\n",
    "        for i in range(3,len(textlist)-1):\n",
    "            if textlist[i] == 3 or  textlist[i] == 9:\n",
    "                continue\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < self.num:\n",
    "#                textlist.pop(i)\n",
    "                textlist = torch.cat([textlist[0:i], textlist[i+1:], torch.tensor([3])])\n",
    "#                print(textlist)\n",
    "        return textlist\n",
    "\n",
    "class randswap(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        counter = 0\n",
    "        #rs_sents = np.zeros(len(textlist), dtype=object)\n",
    "        for i in range(len(textlist)):\n",
    "            while self.num > counter:\n",
    "                box = 0\n",
    "                random_idx_1 = random.randint(1, len(textlist)-1)\n",
    "                while textlist[random_idx_1] == 3 or textlist[random_idx_1] == 9:\n",
    "                    random_idx_1 = random.randint(0, len(textlist)-1)\n",
    "                random_idx_2 = random.randint(1, len(textlist)-1)\n",
    "                while random_idx_1 == random_idx_2 or textlist[random_idx_2] == 3 or textlist[random_idx_1] == 9:\n",
    "                    random_idx_2 = random.randint(0, len(textlist)-1)\n",
    "                    # print(random_idx_1, random_idx_2)\n",
    "                box = textlist[random_idx_1]\n",
    "                textlist[random_idx_1] = textlist[random_idx_2]\n",
    "                textlist[random_idx_2] = box\n",
    "                counter += 1\n",
    "        return textlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tensor Dataset\n",
    "https://stackoverflow.com/questions/55588201/pytorch-transforms-on-tensordataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブドアニュースコーパスをダウンロード\n",
    "\n",
    "    ダウンロードしたファイルは圧縮（tar.gz形式）ファイル\n",
    "    様々なジャンル（IT,スポーツ,家電,映画など）のWEBメディアごとにフォルダに記事がテキストファイルで保存されている\n",
    "    \n",
    "以下、ファイルを読み込んで、必要な部分を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "'''\n",
    "#urllib.request.urlretrieve(\"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\", \"ldcc-20140209.tar.gz\")\n",
    "# ダウンロードした圧縮ファイルのパスを設定\n",
    "#tgz_fname = \"ldcc-20140209.tar.gz\" \n",
    "# 2つをニュースメディアのジャンルを選定\n",
    "mydata = '/export/livedoor' \n",
    "'''\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if articletype == 0:\n",
    "    directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/it-life-hack']\n",
    "    target_genre = [\"dokujo-tsushin\", \"it-life-hack\"]\n",
    "elif articletype == 1:\n",
    "    directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/peachy']\n",
    "    target_genre = [\"dokujo-tsushin\", \"peachy\"]\n",
    "else:\n",
    "    print('No articles')\n",
    "    exit()\n",
    "\n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "        \n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "#        if os.path.isfile(f):\n",
    "#            print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHvN-a5eBOAz"
   },
   "source": [
    "pandasでデータを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1661699114833,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "ks8ElHxNBLkJ",
    "outputId": "ec1e362f-f5e8-4e46-a292-61b26861585d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "\n",
    "if articletype == 0:\n",
    "    df_ = pd.read_csv(\"summary_set_dokujo_it.tsv\", \n",
    "                     delimiter='\\t', header=None, names=['summaries'])\n",
    "elif articletype == 1:\n",
    "    df_ = pd.read_csv(\"summary_set_dokujo_peachy.tsv\", \n",
    "                     delimiter='\\t', header=None, names=['summaries'])\n",
    "\n",
    "# データの確認\n",
    "#print(f'データサイズ： {df.shape}')\n",
    "#print(df_.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JN4ssEmBWda"
   },
   "source": [
    "//文章データをsentences、ラベルデータを labelsに保存、以降この2変数だけを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df.media_name.values\n",
    "labels = df.label.values\n",
    "titles = df.title.values\n",
    "sentences = df.sentence.values\n",
    "summaries = df_.summaries.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"len of summaries:\",len(summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "def make_wakati(sentence):\n",
    "  # MeCabで分かち書きを行う\n",
    "    sentence = tagger.parse(sentence)\n",
    "  # 半角全角英数字などは削除する\n",
    "#    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
    "  # 記号なども削除する\n",
    "#    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
    "  # スペース区切で形態素の配列に変換する\n",
    "    wakati = sentence.split(\" \")\n",
    "  # 空要素を削除する\n",
    "    wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wakati_sentences = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    wakati_sentences.append(make_wakati(sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcount = 256\n",
    "\n",
    "h_sentences = []\n",
    "t_sentences = []\n",
    "\n",
    "# wcount moji me kara kesu\n",
    "\n",
    "for i in enumerate(wakati_sentences):\n",
    "    h_len = 0\n",
    "    hn = 0\n",
    "    h_len += len(wakati_sentences[i[0]][0])\n",
    "    while h_len < wcount:\n",
    "        try:\n",
    "            hn += 1\n",
    "            if wakati_sentences[i[0]][hn]:\n",
    "#                print(hn, wakati_sentences[i[0]][hn])\n",
    "                h_len += len(wakati_sentences[i[0]][hn])\n",
    "        except IndexError:\n",
    "            break\n",
    "    h_sentences.append(sentences[i[0]][:hn])\n",
    "    \n",
    "    t_len = 0\n",
    "    tn = 2\n",
    "    t_len += len(wakati_sentences[i[0]][-2])\n",
    "    while t_len < wcount:\n",
    "        try:\n",
    "            tn += 1\n",
    "            if wakati_sentences[i[0]][tn]:\n",
    "#                print(tn, wakati_sentences[i[0]][tn])\n",
    "                t_len += len(wakati_sentences[i[0]][tn])\n",
    "        except IndexError:\n",
    "            break\n",
    "    t_sentences.append(sentences[i[0]][-tn-20:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(h_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsentences = np.array(h_sentences)\n",
    "tsentences = np.array(t_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssentences = np.array(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ssentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.array(ssentences).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = []\n",
    "asentences = np.append(emp, copy.deepcopy(sentences))\n",
    "ksentences = np.append(emp, copy.deepcopy(sentences))\n",
    "kksentences = np.append(emp, copy.deepcopy(sentences))\n",
    "\n",
    "# wcount moji me kara kesu\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        asentences[i[0]] = sentences[i[0]][:wcount]\n",
    "\n",
    "# ushiro kara wcount moji toru\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        ksentences[i[0]] = sentences[i[0]][-wcount:]\n",
    "\n",
    "# ushiro kara wcount moji toru ichiban ketsu wa toranai\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        am = wcount+20\n",
    "        a = sentences[i[0]][-am:]\n",
    "        kksentences[i[0]] = a[:wcount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ksentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(kksentences[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlNaKoNRBhuo"
   },
   "source": [
    "# BERT Tokenizerを用いて単語分割・IDへ変換\n",
    "## Tokenizerの準備\n",
    "単語分割とIDへ変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ueumK1gF-D2"
   },
   "source": [
    "# テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1661699115434,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "9k0mj33mGD0I",
    "outputId": "9b3f3369-617c-4706-bbd7-7a9d1d0bb7ab"
   },
   "outputs": [],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for sent in hsentences:\n",
    "    # Tokenizeで分割\n",
    "    h_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(h_token_words))\n",
    "for sent in tsentences:\n",
    "    # Tokenizeで分割\n",
    "    t_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(t_token_words))\n",
    "# 最大の値を確認\n",
    "#print('最大単語数: ', max(max_len))\n",
    "#print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicttoken(sentence):\n",
    "    ids = []\n",
    "    masks = []\n",
    "    for sent in sentences:\n",
    "        dict = tokenizer.encode_plus(\n",
    "                sent,                      \n",
    "                add_special_tokens = True, # Special Tokenの追加\n",
    "                max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                truncation=True,                \n",
    "                pad_to_max_length = True,# PADDINGで埋める\n",
    "                return_attention_mask = True,   # Attention maksの作成\n",
    "                return_tensors = 'pt'     #  Pytorch tensorsで返す\n",
    "            )\n",
    "        ids.append(dict['input_ids'])\n",
    "        masks.append(dict['attention_mask'])\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1661699115966,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "-xsginzEGHf5",
    "outputId": "6bf49efd-8a7d-452a-f16a-dd73d5f27b8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h_input_ids, h_attention_masks = dicttoken(hsentences)\n",
    "t_input_ids, t_attention_masks = dicttoken(tsentences)\n",
    "a_input_ids, a_attention_masks = dicttoken(asentences)\n",
    "k_input_ids, k_attention_masks = dicttoken(ksentences)\n",
    "kk_input_ids, kk_attention_masks = dicttoken(kksentences)\n",
    "s_input_ids, s_attention_masks = dicttoken(ssentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "h_input_ids = torch.cat(h_input_ids, dim=0)\n",
    "t_input_ids = torch.cat(t_input_ids, dim=0)\n",
    "a_input_ids = torch.cat(a_input_ids, dim=0)\n",
    "k_input_ids = torch.cat(k_input_ids, dim=0)\n",
    "kk_input_ids = torch.cat(kk_input_ids, dim=0)\n",
    "s_input_ids = torch.cat(s_input_ids, dim=0)\n",
    "h_attention_masks = torch.cat(h_attention_masks, dim=0)\n",
    "t_attention_masks = torch.cat(t_attention_masks, dim=0)\n",
    "a_attention_masks = torch.cat(a_attention_masks, dim=0)\n",
    "k_attention_masks = torch.cat(k_attention_masks, dim=0)\n",
    "kk_attention_masks = torch.cat(kk_attention_masks, dim=0)\n",
    "s_attention_masks = torch.cat(s_attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Original: ', hsentences[0])\\nprint('Original: ', ssentences[0])\\nprint('Token IDs:', s_input_ids[0])\\nprint(type(labels), labels)\\nprint('head')\\nprint(torch.Tensor.size(h_input_ids))\\nprint(torch.Tensor.size(h_attention_masks))\\nprint('summary')\\nprint(torch.Tensor.size(s_input_ids))\\nprint(torch.Tensor.size(s_attention_masks))\\nprint(torch.Tensor.size(labels))\\nprint(ssentences.size)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 確認\n",
    "'''\n",
    "print('Original: ', hsentences[0])\n",
    "print('Original: ', ssentences[0])\n",
    "print('Token IDs:', s_input_ids[0])\n",
    "print(type(labels), labels)\n",
    "print('head')\n",
    "print(torch.Tensor.size(h_input_ids))\n",
    "print(torch.Tensor.size(h_attention_masks))\n",
    "print('summary')\n",
    "print(torch.Tensor.size(s_input_ids))\n",
    "print(torch.Tensor.size(s_attention_masks))\n",
    "print(torch.Tensor.size(labels))\n",
    "print(ssentences.size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1661699115968,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "uX3Hz3YNGKhH",
    "outputId": "bcba9374-dc24-4067-f46c-fa3d6343511c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# データセットクラスの作成\n",
    "# dataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "hdataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "tdataset = TensorDataset(t_input_ids, t_attention_masks, labels)\n",
    "adataset = TensorDataset(a_input_ids, a_attention_masks, labels)\n",
    "kdataset = TensorDataset(k_input_ids, k_attention_masks, labels)\n",
    "kkdataset = TensorDataset(kk_input_ids, kk_attention_masks, labels)\n",
    "sdataset = TensorDataset(s_input_ids, s_attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(hdataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataset = len(hdataset)\n",
    "#train_size = int(0.1 * num_dataset)\n",
    "#val_size = num_dataset - train_size\n",
    "\n",
    "train_size = numof_learn\n",
    "val_size = len(hdataset) - train_size\n",
    "\n",
    "#print('訓練データ数:{}'.format(train_size))\n",
    "#print('検証データ数:{}'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transfomers: ['r', 'i', 'd', 's']\n",
      "synreplace\n",
      "randinsert\n",
      "randdelete\n",
      "randswap\n"
     ]
    }
   ],
   "source": [
    "# データローダーの作成\n",
    "print(\"transfomers:\", transformflags)\n",
    "transformmethods = []\n",
    "if 'r' in transformflags:\n",
    "    transformmethods.append(synreplace(synreplace_rate))\n",
    "    print(\"synreplace\")\n",
    "if 'i' in transformflags:\n",
    "    transformmethods.append(randinsert(randinsert_rate))\n",
    "    print(\"randinsert\")\n",
    "if 'd' in transformflags:\n",
    "    transformmethods.append(randdelete(randdelete_rate))\n",
    "    print(\"randdelete\")\n",
    "if 's' in transformflags:\n",
    "    transformmethods.append(randswap(randswap_rate))\n",
    "    print(\"randswap\")\n",
    "data_transform = transforms.Compose(transformmethods)\n",
    "\n",
    "class MySubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xa, mask, label = self.dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            xa = self.transform(xa)\n",
    "        return xa, mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "indices = np.random.choice(num_dataset, num_dataset, replace=False)\n",
    "\n",
    "# データセットを分割\n",
    "# http://localhost:8888/notebooks/bert-zuco/augmentation/BERTclassification-mydata-local-augmentation-aug.ipynb\n",
    "h_train_dataset, h_val_dataset = random_split(hdataset, [train_size, val_size])\n",
    "t_train_dataset, t_val_dataset = random_split(tdataset, [train_size, val_size])\n",
    "a_train_dataset, a_val_dataset = random_split(adataset, [train_size, val_size])\n",
    "k_train_dataset, k_val_dataset = random_split(kdataset, [train_size, val_size])\n",
    "kk_train_dataset, kk_val_dataset = random_split(kkdataset, [train_size, val_size])\n",
    "s_train_dataset, s_val_dataset = random_split(sdataset, [train_size, val_size])\n",
    "\n",
    "h_train_dataset = MySubset(hdataset, indices[:train_size], data_transform)\n",
    "h_val_dataset = MySubset(hdataset, indices[train_size:])\n",
    "t_train_dataset = MySubset(tdataset, indices[:train_size], data_transform)\n",
    "t_val_dataset = MySubset(tdataset, indices[train_size:])\n",
    "a_train_dataset = MySubset(adataset, indices[:train_size], data_transform)\n",
    "a_val_dataset = MySubset(adataset, indices[train_size:])\n",
    "k_train_dataset = MySubset(kdataset, indices[:train_size], data_transform)\n",
    "k_val_dataset = MySubset(kdataset, indices[train_size:])\n",
    "kk_train_dataset = MySubset(kkdataset, indices[:train_size], data_transform)\n",
    "kk_val_dataset = MySubset(kkdataset, indices[train_size:])\n",
    "s_train_dataset = MySubset(sdataset, indices[:train_size], data_transform)\n",
    "s_val_dataset = MySubset(sdataset, indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データローダー\n",
    "# shuffle True/False to compare or not\n",
    "# wakati head\n",
    "h_train_dataloader = DataLoader(\n",
    "            h_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "# wakati tail\n",
    "t_train_dataloader = DataLoader(\n",
    "            t_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "# letters atama\n",
    "a_train_dataloader = DataLoader(\n",
    "            a_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "#letters ketsu\n",
    "k_train_dataloader = DataLoader(\n",
    "            k_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "# letters ketsu -10\n",
    "kk_train_dataloader = DataLoader(\n",
    "            kk_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "# summary\n",
    "s_train_dataloader = DataLoader(\n",
    "            s_train_dataset, batch_size = batch_size, shuffle = True, num_workers=8)\n",
    "\n",
    "# 検証データローダー\n",
    "h_validation_dataloader = DataLoader(\n",
    "            h_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)\n",
    "t_validation_dataloader = DataLoader(\n",
    "            t_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)\n",
    "a_validation_dataloader = DataLoader(\n",
    "            a_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)\n",
    "k_validation_dataloader = DataLoader(\n",
    "            k_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)\n",
    "kk_validation_dataloader = DataLoader(\n",
    "            kk_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)\n",
    "s_validation_dataloader = DataLoader(\n",
    "            s_val_dataset, batch_size = 1, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9929328cf8d246d2b5be77a5fca18c0f",
      "7ce3a9778e6841e38f6bb2c3d8cfe9b8",
      "8988d5fad2d14b9b97cd311e99093641",
      "e72ccacac3434f939cd0e4adfb3bcc4d",
      "a9503913e9204c7994b76af2f3fd7d3a",
      "105e552bd7bd468f976e099cbe7c74cf",
      "fe1020e5f4eb483fa3fce57764a2508c",
      "9bb08df9e5004f5da8678c2fd10c8eb2",
      "887ca9f3ec9247c4b402bc72745aad0d",
      "50d37681841a449094298dcb52ff9059",
      "9f37d02a0ba944dc9633a68d71891f87",
      "a93d3d99fab445ea80248bd9ae7b0d60",
      "fa68d1e07ae94cd2824d767335a63c64",
      "f69e8de282434b9aa8a457a73593d080",
      "1ed1c48157da42b7bc8719879f3c13c8",
      "7093eae4a1e94e7fbc341564be6a727c",
      "e13d9164a1a6418b87f8fc9f2f5d10eb",
      "c7b849cdaf324e108283b9930d31ec7e",
      "a6e9829602e047f5ab93e3dfb66195cb",
      "baa09b17fcba4d8593e8155907a72c31",
      "7481c5bc470c42cf8ef6d38b69c4ce8a",
      "240f4e1960d44c189adf177c9eb4a17e"
     ]
    },
    "executionInfo": {
     "elapsed": 28456,
     "status": "ok",
     "timestamp": 1661699144410,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "tXUhEdWTGPRs",
    "outputId": "f525692a-ffa0-49cf-a54c-0f91707721b0"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "def loadmodel():\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "        num_labels = 2, # ラベル数（今回はBinaryなので2、数値を増やせばマルチラベルも対応可）\n",
    "        output_attentions = False, # アテンションベクトルを出力するか\n",
    "        output_hidden_states = False, # 隠れ層を出力するか\n",
    "    ).to(device)\n",
    "    # 最適化手法の設定\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import OrderedDict\n",
    "\n",
    "alloutputs = []\n",
    "\n",
    "def train(epoch, model, optimizer, dataloader):\n",
    "    model.train() # 訓練モードで実行\n",
    "    train_loss = 0\n",
    "    with tqdm(dataloader) as pbar:\n",
    "        pbar.set_description(f'[Epoch {epoch + 1}/{max_epoch}]')\n",
    "        for iteration, batch in enumerate(dataloader):\n",
    "#    for batch in dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(b_input_ids, \n",
    "                                 token_type_ids=None, \n",
    "                                 attention_mask=b_input_mask, \n",
    "                                 labels=b_labels)\n",
    "            loss = output.loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lossi = loss.item()\n",
    "            pbar.set_postfix(\n",
    "                OrderedDict(\n",
    "                    Loss=lossi\n",
    "                )\n",
    "            )\n",
    "            wandb.log({'epoch': epoch, 'loss': lossi})\n",
    "            train_loss += lossi\n",
    "#                print(output)\n",
    "#                print(output['logits'])\n",
    "            alloutputs.append(output['logits'].to('cpu'))\n",
    "    return train_loss, alloutputs\n",
    "\n",
    "def validation(model, dataloader):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    val_loss = 0\n",
    "    alloutputs = []\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        with tqdm(dataloader) as pbar:\n",
    "            for iteration, batch in enumerate(dataloader):\n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_input_mask = batch[1].to(device)\n",
    "                b_labels = batch[2].to(device)\n",
    "                with torch.no_grad():        \n",
    "                    output = model(b_input_ids, \n",
    "                                        token_type_ids=None, \n",
    "                                        attention_mask=b_input_mask,\n",
    "                                        labels=b_labels)\n",
    "                loss = output.loss\n",
    "                preds = output.logits.argmax(axis=1)\n",
    "                alloutputs.append(output.logits.to('cpu').clone())\n",
    "                lossi = loss.item()\n",
    "                pbar.set_postfix(\n",
    "                    OrderedDict(\n",
    "                        Loss=lossi,\n",
    "                        Accuracy=torch.sum(preds == b_labels).item() / len(b_labels),\n",
    "                        Len=len(alloutputs)\n",
    "                    )\n",
    "                )\n",
    "                wandb.log({'epoch': epoch, 'loss': lossi})\n",
    "                if numof_validation < iteration:\n",
    "#                    print('validation quit')\n",
    "                    break\n",
    "    return loss, alloutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "iPwWkV3HJtaG"
   },
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "t_train_loss_ = []\n",
    "t_test_loss_ = []\n",
    "h_train_loss_ = []\n",
    "h_test_loss_ = []\n",
    "a_train_loss_ = []\n",
    "a_test_loss_ = []\n",
    "k_train_loss_ = []\n",
    "k_test_loss_ = []\n",
    "kk_train_loss_ = []\n",
    "kk_test_loss_ = []\n",
    "s_train_loss_ = []\n",
    "s_test_loss_ = []\n",
    "\n",
    "h_train_loss = 0\n",
    "t_train_loss = 0\n",
    "a_train_loss = 0\n",
    "k_train_loss = 0\n",
    "kk_train_loss = 0\n",
    "s_train_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzukoewest\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/export/liBERTy/ensemble/wandb/run-20230102_033938-o9ytj0ym</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/zukoewest/liBERTy-re2-h/runs/o9ytj0ym\" target=\"_blank\">cool-moon-138</a></strong> to <a href=\"https://wandb.ai/zukoewest/liBERTy-re2-h\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[Epoch 1/1]:   0%|                                                                                        | 0/1 [00:58<?, ?it/s, Loss=0.727]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c0564df3e4dd8842aef66ef76a078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.483475…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.72652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-moon-138</strong>: <a href=\"https://wandb.ai/zukoewest/liBERTy-re2-h/runs/o9ytj0ym\" target=\"_blank\">https://wandb.ai/zukoewest/liBERTy-re2-h/runs/o9ytj0ym</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230102_033938-o9ytj0ym/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343f4b6f0e1945179717ca0c8816acb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666937928336362, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/export/liBERTy/ensemble/wandb/run-20230102_034045-6y3p7s6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/zukoewest/liBERTy-re2-h-v/runs/6y3p7s6i\" target=\"_blank\">distinctive-durian-125</a></strong> to <a href=\"https://wandb.ai/zukoewest/liBERTy-re2-h-v\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/1690 [00:00<?, ?it/s, Loss=0.909, Accuracy=0, Len=171]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m      9\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliBERTy-re2-h-v\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m h_test_loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_validation_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[42], line 49\u001b[0m, in \u001b[0;36mvalidation\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     47\u001b[0m b_labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():        \n\u001b[0;32m---> 49\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     54\u001b[0m preds \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1566\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1566\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1580\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1021\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1014\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1015\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1016\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1020\u001b[0m )\n\u001b[0;32m-> 1021\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1034\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:496\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    486\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    495\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    418\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 426\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    436\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:285\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    284\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 285\u001b[0m     mixed_query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# and values come from an encoder; the attention mask needs to be\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/lecml/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"liBERTy-re2-h\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    h_train_ = train(epoch, model, optimizer,  h_train_dataloader)\n",
    "    h_train_loss_.append(h_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-h-v\")\n",
    "h_test_loss_ = validation(model, h_validation_dataloader)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"liBERTy-re2-t\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    t_train_ = train(epoch, model, optimizer,  t_train_dataloader)\n",
    "    t_train_loss_.append(t_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-t-v\")\n",
    "t_test_loss_ = validation(model, t_validation_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"liBERTy-re2-a\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    a_train_ = train(epoch, model, optimizer,  a_train_dataloader)\n",
    "    a_train_loss_.append(a_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-a-v\")\n",
    "a_test_loss_ = validation(model, a_validation_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"liBERTy-re2-k\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    k_train_ = train(epoch, model, optimizer,  k_train_dataloader)\n",
    "    k_train_loss_.append(k_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-k-v\")\n",
    "k_test_loss_ = validation(model, k_validation_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"liBERTy-re2-kk\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    kk_train_ = train(epoch, model, optimizer,  kk_train_dataloader)\n",
    "    kk_train_loss_.append(kk_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-kk-v\")\n",
    "kk_test_loss_ = validation(model, kk_validation_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"liBERTy-re2-s\")\n",
    "model, optimizer = loadmodel()\n",
    "for epoch in range(max_epoch):\n",
    "    s_train_ = train(epoch, model, optimizer,  s_train_dataloader)\n",
    "    s_train_loss_.append(s_train_)\n",
    "#    if epoch%10 == 0:\n",
    "#        print('epoch: ', epoch)\n",
    "wandb.finish()\n",
    "wandb.init(project=\"liBERTy-re2-s-v\")\n",
    "s_test_loss_ = validation(model, s_validation_dataloader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    sents.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[i])))\n",
    "\n",
    "#print(sents)\n",
    "sents = pd.DataFrame(sents)\n",
    "#print(type(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type soroete X train test Y train test wo kaizan suru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pred_ = []\n",
    "t_pred_ = []\n",
    "a_pred_ = []\n",
    "k_pred_ = []\n",
    "kk_pred_ = []\n",
    "s_pred_ = []\n",
    "\n",
    "for i in range(len(h_test_loss_[1])):\n",
    "    h_pred_.append(np.argmax(np.array(h_test_loss_[1][i])))\n",
    "    t_pred_.append(np.argmax(np.array(t_test_loss_[1][i])))\n",
    "    a_pred_.append(np.argmax(np.array(a_test_loss_[1][i])))\n",
    "    k_pred_.append(np.argmax(np.array(k_test_loss_[1][i])))\n",
    "    kk_pred_.append(np.argmax(np.array(kk_test_loss_[1][i])))\n",
    "    s_pred_.append(np.argmax(np.array(s_test_loss_[1][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlabel = []\n",
    "for _,_,label in h_validation_dataloader:\n",
    "    # preventing Too many open files Error\n",
    "    vlabel.append(copy.deepcopy(label.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pred_df = pd.DataFrame(h_pred_, columns=['h_pred_label'])\n",
    "t_pred_df = pd.DataFrame(t_pred_, columns=['t_pred_label'])\n",
    "a_pred_df = pd.DataFrame(a_pred_, columns=['a_pred_label'])\n",
    "k_pred_df = pd.DataFrame(k_pred_, columns=['k_pred_label'])\n",
    "kk_pred_df = pd.DataFrame(kk_pred_, columns=['kk_pred_label'])\n",
    "s_pred_df = pd.DataFrame(s_pred_, columns=['s_pred_label'])\n",
    "label_df = pd.DataFrame(vlabel, columns=['true_label'])\n",
    "accuracy_df = pd.concat([h_pred_df, t_pred_df, a_pred_df, k_pred_df, kk_pred_df, s_pred_df, label_df], axis=1)\n",
    "accuracy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpreds = h_pred_df.values\n",
    "tpreds = t_pred_df.values\n",
    "apreds = a_pred_df.values\n",
    "kpreds = k_pred_df.values\n",
    "kkpreds = kk_pred_df.values\n",
    "spreds = s_pred_df.values\n",
    "preds = []\n",
    "pred = 0\n",
    "m = 7\n",
    "\n",
    "for i in range(len(hpreds)):\n",
    "    pred = hpreds[i]+tpreds[i]+apreds[i]+kpreds[i]+kkpreds[i]+spreds[i]\n",
    "    if pred/m < 0.5:\n",
    "        pred = 0\n",
    "    else:\n",
    "        pred = 1\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds, columns=['pred_label'])\n",
    "label_df = pd.DataFrame(vlabel, columns=['true_label'])\n",
    "ensaccuracy_df = pd.concat([preds_df, label_df], axis=1)\n",
    "#ensaccuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred_label accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = 0\n",
    "ypnum = 0 #yosoku\n",
    "spnum = 0 #seikai\n",
    "pnum = 0\n",
    "rnum = 0\n",
    "for i in range(len(preds_df)):\n",
    "    if preds_df.values[i] == label_df.values[i]:\n",
    "        cor += 1\n",
    "    if preds_df.values[i] == 0:\n",
    "        ypnum += 1\n",
    "        if label_df.values[i] == 0:\n",
    "            pnum += 1\n",
    "    if label_df.values[i] == 0:\n",
    "        spnum += 1\n",
    "        if preds_df.values[i] == 0:\n",
    "            rnum += 1\n",
    "        \n",
    "100*cor/len(preds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred_label F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# tekigou\n",
    "tp = pnum/ypnum\n",
    "# saigen\n",
    "sp = rnum/spnum\n",
    "(tp*sp)/(tp+sp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def accuracy(pdf):\n",
    "    return (pdf == label_df.values[:len(pdf)]).sum()/len(pdf)\n",
    "\n",
    "def fscore(pdf):\n",
    "    return f1_score(pdf, label_df.values[:len(pdf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('head', accuracy(hpreds), fscore(hpreds))\n",
    "print('tail', accuracy(tpreds), fscore(tpreds))\n",
    "print('atama', accuracy(apreds), fscore(apreds))\n",
    "print('ketsu', accuracy(kpreds), fscore(kpreds))\n",
    "print('ketsu-10', accuracy(kkpreds), fscore(kkpreds))\n",
    "print('summary', accuracy(spreds), fscore(spreds))\n",
    "print('all', accuracy(preds_df.values), fscore(preds_df.values))\n",
    "\n",
    "f = open('acc'+filestr+'.csv', 'w')\n",
    "f.write('head,'+str(accuracy(hpreds))+','+str(fscore(hpreds))+'\\n')\n",
    "f.write('tail,'+str(accuracy(tpreds))+','+str(fscore(tpreds))+'\\n')\n",
    "f.write('atama,'+str(accuracy(apreds))+','+str(fscore(apreds))+'\\n')\n",
    "f.write('ketsu,'+str(accuracy(kpreds))+','+str(fscore(kpreds))+'\\n')\n",
    "f.write('ketsu-10,'+str(accuracy(kkpreds))+','+str(fscore(kkpreds))+'\\n')\n",
    "f.write('summary,'+str(accuracy(spreds))+','+str(fscore(spreds))+'\\n')\n",
    "f.write('all,'+str(accuracy(preds_df.values))+','+str(fscore(preds_df.values))+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train_loss = []\n",
    "T_train_loss = []\n",
    "A_train_loss = []\n",
    "K_train_loss = []\n",
    "KK_train_loss = []\n",
    "S_train_loss = []\n",
    "\n",
    "for i in range(max_epoch):\n",
    "    H_train_loss.append(h_train_loss_[i][0])\n",
    "    T_train_loss.append(t_train_loss_[i][0])\n",
    "    A_train_loss.append(a_train_loss_[i][0])\n",
    "    K_train_loss.append(k_train_loss_[i][0])\n",
    "    KK_train_loss.append(kk_train_loss_[i][0])\n",
    "    S_train_loss.append(s_train_loss_[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('ens_augens-re2-rep-'+filestr+'.csv', 'w')\n",
    "f.write('H, T, A, K, KK, S\\n')\n",
    "writer = csv.writer(f)\n",
    "writer.writerows(map(lambda h, t, a, k, kk, s: [h, t, a, k, kk, s], H_train_loss, T_train_loss, A_train_loss,\n",
    "                  K_train_loss, KK_train_loss, S_train_loss))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(H_train_loss)), H_train_loss, label=\"Head\")\n",
    "plt.plot(range(len(T_train_loss)), T_train_loss, label=\"Tail\")\n",
    "plt.plot(range(len(A_train_loss)), A_train_loss, label=\"WakatiHead\")\n",
    "plt.plot(range(len(K_train_loss)), K_train_loss, label=\"WakatiTail\")\n",
    "plt.plot(range(len(KK_train_loss)), KK_train_loss, label=\"WakatiTail-10\")\n",
    "plt.plot(range(len(S_train_loss)), S_train_loss, label=\"Summary\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"ens_augens-re2-fig-\"+filestr+\".png\", format=\"png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERTclassification.ipynb",
   "provenance": [
    {
     "file_id": "1mxMTVW123hMPhZLg9UjVEhkL_vrFvMp7",
     "timestamp": 1659890794413
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08a0764a15bb4b45ab9bfdbe3a02c318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b407dd3170f4f55be7f8708c59d262b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5616789e354d45699ea2040757dbd5c3",
       "IPY_MODEL_d6bc8aac6ca74bff92bba66f17c20b00",
       "IPY_MODEL_96fb1e06ef4349b5b6a071be230a711c"
      ],
      "layout": "IPY_MODEL_8d05e54e5fc644d2a3c974758c5e439c"
     }
    },
    "105e552bd7bd468f976e099cbe7c74cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11cc64e4ce0843ae88a651762d68b844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1aff4434a10549e387f749140d4721f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ed1c48157da42b7bc8719879f3c13c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7481c5bc470c42cf8ef6d38b69c4ce8a",
      "placeholder": "​",
      "style": "IPY_MODEL_240f4e1960d44c189adf177c9eb4a17e",
      "value": " 424M/424M [00:15&lt;00:00, 54.9MB/s]"
     }
    },
    "240f4e1960d44c189adf177c9eb4a17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dc2139703bb4448969390f2a91e00f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994b8f69c284d758c5f04deeb3fcca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "423c0b6849204bbc96c7b039633373f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4535f833bfac4540a8add9686f623b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9279616c547b47de92a436ebb026fd79",
      "max": 153,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3910389daf34e31af5f33ef7d539625",
      "value": 153
     }
    },
    "45555846fc9746af9a06d76c6c9aee1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46351ebb1bfd41b5b9fbc4de40e218e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50d37681841a449094298dcb52ff9059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5616789e354d45699ea2040757dbd5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a20acb0a8fc4320af5a849c9d780649",
      "placeholder": "​",
      "style": "IPY_MODEL_45555846fc9746af9a06d76c6c9aee1b",
      "value": "Downloading spiece.model: 100%"
     }
    },
    "705cf2ba17614d51853eeb9dfc74d540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3994b8f69c284d758c5f04deeb3fcca1",
      "max": 259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08a0764a15bb4b45ab9bfdbe3a02c318",
      "value": 259
     }
    },
    "7093eae4a1e94e7fbc341564be6a727c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fb8df2799443d996d165878dc526a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9f368ede2d24e3095242e9a3cf8c545",
       "IPY_MODEL_4535f833bfac4540a8add9686f623b54",
       "IPY_MODEL_7803695cfa5742bf85208ee04193acb0"
      ],
      "layout": "IPY_MODEL_423c0b6849204bbc96c7b039633373f9"
     }
    },
    "7481c5bc470c42cf8ef6d38b69c4ce8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7803695cfa5742bf85208ee04193acb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d808ec79b0dd465a82077ca7f2c8feb6",
      "placeholder": "​",
      "style": "IPY_MODEL_d2a46f9221b14f86a3330510812f258e",
      "value": " 153/153 [00:00&lt;00:00, 4.82kB/s]"
     }
    },
    "7ce3a9778e6841e38f6bb2c3d8cfe9b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_105e552bd7bd468f976e099cbe7c74cf",
      "placeholder": "​",
      "style": "IPY_MODEL_fe1020e5f4eb483fa3fce57764a2508c",
      "value": "Downloading config.json: 100%"
     }
    },
    "83cf06c42be34c068dbbf6fcc5cfd6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f629f372d73b44efb31e8d7c5a45d4cd",
      "placeholder": "​",
      "style": "IPY_MODEL_93c25b4c96e64fecbb7f569527e50722",
      "value": " 259/259 [00:00&lt;00:00, 8.26kB/s]"
     }
    },
    "887ca9f3ec9247c4b402bc72745aad0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8988d5fad2d14b9b97cd311e99093641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bb08df9e5004f5da8678c2fd10c8eb2",
      "max": 479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_887ca9f3ec9247c4b402bc72745aad0d",
      "value": 479
     }
    },
    "8d05e54e5fc644d2a3c974758c5e439c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9279616c547b47de92a436ebb026fd79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "937dd0c1d06e4d69824b7be991cc52f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c25b4c96e64fecbb7f569527e50722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96fb1e06ef4349b5b6a071be230a711c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd4beed83d947b9a5eec5918dcd2319",
      "placeholder": "​",
      "style": "IPY_MODEL_1aff4434a10549e387f749140d4721f4",
      "value": " 787k/787k [00:00&lt;00:00, 11.4MB/s]"
     }
    },
    "9929328cf8d246d2b5be77a5fca18c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ce3a9778e6841e38f6bb2c3d8cfe9b8",
       "IPY_MODEL_8988d5fad2d14b9b97cd311e99093641",
       "IPY_MODEL_e72ccacac3434f939cd0e4adfb3bcc4d"
      ],
      "layout": "IPY_MODEL_a9503913e9204c7994b76af2f3fd7d3a"
     }
    },
    "9a20acb0a8fc4320af5a849c9d780649": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9b67b9ebf94a13a95e759a696c884f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bb08df9e5004f5da8678c2fd10c8eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f37d02a0ba944dc9633a68d71891f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0880f15772d4156a9eb94d6314c2d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e9829602e047f5ab93e3dfb66195cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93d3d99fab445ea80248bd9ae7b0d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa68d1e07ae94cd2824d767335a63c64",
       "IPY_MODEL_f69e8de282434b9aa8a457a73593d080",
       "IPY_MODEL_1ed1c48157da42b7bc8719879f3c13c8"
      ],
      "layout": "IPY_MODEL_7093eae4a1e94e7fbc341564be6a727c"
     }
    },
    "a9503913e9204c7994b76af2f3fd7d3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3910389daf34e31af5f33ef7d539625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baa09b17fcba4d8593e8155907a72c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7b849cdaf324e108283b9930d31ec7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f368ede2d24e3095242e9a3cf8c545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_937dd0c1d06e4d69824b7be991cc52f0",
      "placeholder": "​",
      "style": "IPY_MODEL_11cc64e4ce0843ae88a651762d68b844",
      "value": "Downloading special_tokens_map.json: 100%"
     }
    },
    "cfd1b9e85db447fbaf01f66f6f0f6429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dc2139703bb4448969390f2a91e00f6",
      "placeholder": "​",
      "style": "IPY_MODEL_46351ebb1bfd41b5b9fbc4de40e218e3",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "d2a46f9221b14f86a3330510812f258e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d337eb6795e241389d9b35805a59fc22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6bc8aac6ca74bff92bba66f17c20b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0880f15772d4156a9eb94d6314c2d9e",
      "max": 805634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d337eb6795e241389d9b35805a59fc22",
      "value": 805634
     }
    },
    "d808ec79b0dd465a82077ca7f2c8feb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd6aadfe79224713b5a47dd108ff71b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfd1b9e85db447fbaf01f66f6f0f6429",
       "IPY_MODEL_705cf2ba17614d51853eeb9dfc74d540",
       "IPY_MODEL_83cf06c42be34c068dbbf6fcc5cfd6d5"
      ],
      "layout": "IPY_MODEL_9a9b67b9ebf94a13a95e759a696c884f"
     }
    },
    "e13d9164a1a6418b87f8fc9f2f5d10eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e72ccacac3434f939cd0e4adfb3bcc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50d37681841a449094298dcb52ff9059",
      "placeholder": "​",
      "style": "IPY_MODEL_9f37d02a0ba944dc9633a68d71891f87",
      "value": " 479/479 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "efd4beed83d947b9a5eec5918dcd2319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f629f372d73b44efb31e8d7c5a45d4cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69e8de282434b9aa8a457a73593d080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6e9829602e047f5ab93e3dfb66195cb",
      "max": 445021143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baa09b17fcba4d8593e8155907a72c31",
      "value": 445021143
     }
    },
    "fa68d1e07ae94cd2824d767335a63c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e13d9164a1a6418b87f8fc9f2f5d10eb",
      "placeholder": "​",
      "style": "IPY_MODEL_c7b849cdaf324e108283b9930d31ec7e",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "fe1020e5f4eb483fa3fce57764a2508c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
