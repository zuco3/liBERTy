{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wcOk2ZzAAQr"
   },
   "source": [
    "# Hugging Face Library 'Transformer'およびT5Tokenizerのダウンロード\n",
    "\n",
    "参考(https://qiita.com/takubb/items/fd972f0ac3dba909c293)これを基に改造し、最新のGoogle Colaboratoryで動作するようにした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0b407dd3170f4f55be7f8708c59d262b",
      "5616789e354d45699ea2040757dbd5c3",
      "d6bc8aac6ca74bff92bba66f17c20b00",
      "96fb1e06ef4349b5b6a071be230a711c",
      "8d05e54e5fc644d2a3c974758c5e439c",
      "9a20acb0a8fc4320af5a849c9d780649",
      "45555846fc9746af9a06d76c6c9aee1b",
      "a0880f15772d4156a9eb94d6314c2d9e",
      "d337eb6795e241389d9b35805a59fc22",
      "efd4beed83d947b9a5eec5918dcd2319",
      "1aff4434a10549e387f749140d4721f4",
      "73fb8df2799443d996d165878dc526a8",
      "c9f368ede2d24e3095242e9a3cf8c545",
      "4535f833bfac4540a8add9686f623b54",
      "7803695cfa5742bf85208ee04193acb0",
      "423c0b6849204bbc96c7b039633373f9",
      "937dd0c1d06e4d69824b7be991cc52f0",
      "11cc64e4ce0843ae88a651762d68b844",
      "9279616c547b47de92a436ebb026fd79",
      "b3910389daf34e31af5f33ef7d539625",
      "d808ec79b0dd465a82077ca7f2c8feb6",
      "d2a46f9221b14f86a3330510812f258e",
      "dd6aadfe79224713b5a47dd108ff71b9",
      "cfd1b9e85db447fbaf01f66f6f0f6429",
      "705cf2ba17614d51853eeb9dfc74d540",
      "83cf06c42be34c068dbbf6fcc5cfd6d5",
      "9a9b67b9ebf94a13a95e759a696c884f",
      "2dc2139703bb4448969390f2a91e00f6",
      "46351ebb1bfd41b5b9fbc4de40e218e3",
      "3994b8f69c284d758c5f04deeb3fcca1",
      "08a0764a15bb4b45ab9bfdbe3a02c318",
      "f629f372d73b44efb31e8d7c5a45d4cd",
      "93c25b4c96e64fecbb7f569527e50722"
     ]
    },
    "executionInfo": {
     "elapsed": 30796,
     "status": "ok",
     "timestamp": 1661865111605,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "DJ__bXJq_06p",
    "outputId": "b2d9fbba-45cc-4348-fadf-7b15798ffd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing_extensions in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: numpy in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: torch in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: transformers in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: sacremoses in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: click in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "# !pip install torch\n",
    "!pip install torchvision\n",
    "!pip install transformers\n",
    "#!apt install swig\n",
    "# Sentencepieceのインストール\n",
    "!pip install sentencepiece\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
    "import gzip\n",
    "import shutil\n",
    "import sqlite3\n",
    "import random\n",
    "from math import ceil\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import torchvision\n",
    "import statistics\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpCa2h0oAU51"
   },
   "source": [
    "# PyTorchとGPU設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5548,
     "status": "ok",
     "timestamp": 1661865117146,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "hLV4lS8CAWCZ",
    "outputId": "6fa5cea1-0ec6-4aa3-82d5-53328e8b1c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation kansuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synreplace - replace kasho kosuu\n",
    "# randinsert - tasu kotoba no kazu\n",
    "# randdelete - delete kakuritsu\n",
    "# randswap - swap kaisuu\n",
    "\n",
    "class synreplace(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        self.model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "    def __call__(self, textlist):\n",
    "        # textlist: honbun no list\n",
    "        textlen = torch.where(textlist == 3)[0][0]\n",
    "        for n in range(self.num):\n",
    "            # chikan shiro\n",
    "            masked_idx = random.randint(2, textlen-1)\n",
    "            textlist[masked_idx] = 6\n",
    "            # convert to tensor\n",
    "            token_tensor = torch.tensor(textlist)\n",
    "            # get the top 10 predictions of the masked token\n",
    "            self.model = self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(torch.unsqueeze(token_tensor, 0))\n",
    "                predictions = outputs[0][0, masked_idx].topk(1)\n",
    "            for i, index_t in enumerate(predictions.indices):\n",
    "                index = index_t.item()\n",
    "            textlist[masked_idx] = index\n",
    "        return textlist\n",
    "\n",
    "class randinsert(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        for n in range(self.num):\n",
    "            insword = textlist[random.randint(1,len(textlist)-1)]\n",
    "            i = random.randint(1,len(textlist)-1)\n",
    "#            print('len: ', len(textlist))\n",
    "#            print(i)\n",
    "            while textlist[i] == 3:\n",
    "                i = random.randint(1,len(textlist)-1)\n",
    "#                print(i)\n",
    "            textlist = torch.cat([textlist[0:i], torch.tensor([insword]), textlist[i:-1]])\n",
    "        return textlist\n",
    "\n",
    "class randdelete(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "#        print(textlist.shape)\n",
    "        for i in range(3,len(textlist)-1):\n",
    "            if textlist[i] == 3:\n",
    "                continue\n",
    "            r = random.uniform(0, 1)\n",
    "            if r < self.num:\n",
    "#                textlist.pop(i)\n",
    "                textlist = torch.cat([textlist[0:i], textlist[i+1:], torch.tensor([3])])\n",
    "#                print(textlist)\n",
    "        return textlist\n",
    "\n",
    "class randswap(object):\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "    def __call__(self, textlist):\n",
    "        counter = 0\n",
    "        #rs_sents = np.zeros(len(textlist), dtype=object)\n",
    "        for i in range(len(textlist)):\n",
    "            while self.num > counter:\n",
    "                box = 0\n",
    "                random_idx_1 = random.randint(1, len(textlist)-1)\n",
    "                while textlist[random_idx_1] == 3:\n",
    "                    random_idx_1 = random.randint(0, len(textlist)-1)\n",
    "                random_idx_2 = random.randint(1, len(textlist)-1)\n",
    "                while random_idx_1 == random_idx_2 or textlist[random_idx_2] == 3:\n",
    "                    random_idx_2 = random.randint(0, len(textlist)-1)\n",
    "                    # print(random_idx_1, random_idx_2)\n",
    "                box = textlist[random_idx_1]\n",
    "                textlist[random_idx_1] = textlist[random_idx_2]\n",
    "                textlist[random_idx_2] = box\n",
    "                counter += 1\n",
    "        return textlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Tensor Dataset\n",
    "https://stackoverflow.com/questions/55588201/pytorch-transforms-on-tensordataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブドアニュースコーパスをダウンロード\n",
    "\n",
    "    ダウンロードしたファイルは圧縮（tar.gz形式）ファイル\n",
    "    様々なジャンル（IT,スポーツ,家電,映画など）のWEBメディアごとにフォルダに記事がテキストファイルで保存されている\n",
    "    \n",
    "以下、ファイルを読み込んで、必要な部分を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urllib.request.urlretrieve(\"https://www.rondhuit.com/download/ldcc-20140209.tar.gz\", \"ldcc-20140209.tar.gz\")\n",
    "# ダウンロードした圧縮ファイルのパスを設定\n",
    "#tgz_fname = \"ldcc-20140209.tar.gz\" \n",
    "# 2つをニュースメディアのジャンルを選定\n",
    "mydata = '/export/livedoor' \n",
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "\"\"\"\n",
    "def read_url(f):\n",
    "    url = next(f)\n",
    "    return url[:-1]\n",
    "\n",
    "def read_date(f):\n",
    "    date = next(f)\n",
    "    date = remove_brackets(date.encode().decode('utf-8'))\n",
    "    return date[:-1]\n",
    "\"\"\"\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/it-life-hack']\n",
    "target_genre = [\"dokujo-tsushin\", \"it-life-hack\"] \n",
    "#directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/peachy']\n",
    "#target_genre = [\"dokujo-tsushin\", \"peachy\"] \n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "        #if os.path.isfile(f):\n",
    "        #    print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHvN-a5eBOAz"
   },
   "source": [
    "pandasでデータを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1661699114833,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "ks8ElHxNBLkJ",
    "outputId": "ec1e362f-f5e8-4e46-a292-61b26861585d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1740, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>現役ホステスに聞く、一番人気のホステスとは</td>\n",
       "      <td>女性が同性を見る目は厳しい。その視線を意地悪ととるかお勉強になりますと前向きにとらえるかで人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>Webページを丸ごと取り込むワザ！知っているとお得なパソコン快適術知っ得！虎の</td>\n",
       "      <td>ふだん何気なく使っているスマートフォンやパソコンだが、ちょっとした工夫やヒントで効率よく仕事...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>シマンテックより警告！メールアドレスを収集する危険なアプリに要注意</td>\n",
       "      <td>シマンテックのセキュリティブログによると、スパム送信用のメールアドレス収集を目的としたAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>いま話題のフレンチトースト！きな粉＆黒蜜味に、明太マヨ味</td>\n",
       "      <td>このところ、朝夕の情報番組や雑誌などでも注目されているフレンチトースト。江ノ島のLONCAF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>コンビニのレジ前でついつい買ってしまうも</td>\n",
       "      <td>日本中、小さな街にもひとつくらいコンビニがある。いつでも気軽に欲しいものが手に入るコンビニは...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>満たされると不安!?ちょっと不幸な私が好き症候</td>\n",
       "      <td>好きになるのはダメ男ばかり二股かけられる率が高いなぜか既婚者にハマってしまうetc。会うたび...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>夏バテよりも深刻な新型秋バテは、1日2回の紅茶でリセット!</td>\n",
       "      <td>あつい日がまだまだ続いていますが、みなさん、節電してますか？もとは私たちの配慮だったはずが、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>くさったよめがあらわれた！vol.06専業主婦ってやることいっぱい、暇じゃないんだから!?p...</td>\n",
       "      <td>スーパーは、閉店間際が狙いどき！こんにちは！うえやま洋介犬の漫画くさったよめがあらわれた！の...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>訊かれて困るクリスマスの過ごし方。貴方の楽しみは</td>\n",
       "      <td>独女にとって、良くも悪くも一年で最も神経が過敏になる季節クリスマスが近づいてきた。彼氏や家族...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>サービス終了後はどうなる！電子書籍は永遠に読めるのかデジ</td>\n",
       "      <td>ソニーコンピュータエンターテイメントのポータブルゲーム機、PSPで配信されていたコミックコン...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          media_name  label  \\\n",
       "137   dokujo-tsushin      0   \n",
       "1228    it-life-hack      1   \n",
       "1581    it-life-hack      1   \n",
       "143   dokujo-tsushin      0   \n",
       "435   dokujo-tsushin      0   \n",
       "394   dokujo-tsushin      0   \n",
       "548   dokujo-tsushin      0   \n",
       "860   dokujo-tsushin      0   \n",
       "698   dokujo-tsushin      0   \n",
       "1373    it-life-hack      1   \n",
       "\n",
       "                                                  title  \\\n",
       "137                               現役ホステスに聞く、一番人気のホステスとは   \n",
       "1228            Webページを丸ごと取り込むワザ！知っているとお得なパソコン快適術知っ得！虎の   \n",
       "1581                  シマンテックより警告！メールアドレスを収集する危険なアプリに要注意   \n",
       "143                        いま話題のフレンチトースト！きな粉＆黒蜜味に、明太マヨ味   \n",
       "435                                コンビニのレジ前でついつい買ってしまうも   \n",
       "394                             満たされると不安!?ちょっと不幸な私が好き症候   \n",
       "548                       夏バテよりも深刻な新型秋バテは、1日2回の紅茶でリセット!   \n",
       "860   くさったよめがあらわれた！vol.06専業主婦ってやることいっぱい、暇じゃないんだから!?p...   \n",
       "698                            訊かれて困るクリスマスの過ごし方。貴方の楽しみは   \n",
       "1373                       サービス終了後はどうなる！電子書籍は永遠に読めるのかデジ   \n",
       "\n",
       "                                               sentence  \n",
       "137   女性が同性を見る目は厳しい。その視線を意地悪ととるかお勉強になりますと前向きにとらえるかで人...  \n",
       "1228  ふだん何気なく使っているスマートフォンやパソコンだが、ちょっとした工夫やヒントで効率よく仕事...  \n",
       "1581  シマンテックのセキュリティブログによると、スパム送信用のメールアドレス収集を目的としたAnd...  \n",
       "143   このところ、朝夕の情報番組や雑誌などでも注目されているフレンチトースト。江ノ島のLONCAF...  \n",
       "435   日本中、小さな街にもひとつくらいコンビニがある。いつでも気軽に欲しいものが手に入るコンビニは...  \n",
       "394   好きになるのはダメ男ばかり二股かけられる率が高いなぜか既婚者にハマってしまうetc。会うたび...  \n",
       "548   あつい日がまだまだ続いていますが、みなさん、節電してますか？もとは私たちの配慮だったはずが、...  \n",
       "860   スーパーは、閉店間際が狙いどき！こんにちは！うえやま洋介犬の漫画くさったよめがあらわれた！の...  \n",
       "698   独女にとって、良くも悪くも一年で最も神経が過敏になる季節クリスマスが近づいてきた。彼氏や家族...  \n",
       "1373  ソニーコンピュータエンターテイメントのポータブルゲーム機、PSPで配信されていたコミックコン...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "# データの確認\n",
    "print(f'データサイズ： {df.shape}')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JN4ssEmBWda"
   },
   "source": [
    "//文章データをsentences、ラベルデータを labelsに保存、以降この2変数だけを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df.media_name.values\n",
    "labels = df.label.values\n",
    "titles = df.title.values\n",
    "sentences = df.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  両親や親族が高齢なってくると、自分の人生を見つめ直さないといけないことがある。自分が独女の場合はなお更である。今回の相談者ミミさん女性38歳は母親が介護が必要になったことを機に働き方を変えたのだが、以降、仕事や人間関係がうまく築けずに悩み続けている。同時に、現在結婚していないことで将来に大きな不安も抱いている。この先、希望を見出すことは出来るのだろうか？霊感鑑定で定評のある占い師翔生先生に鑑定してもらった。占い師翔生先生nifty電話占いメール占い相談内容母の介護が必要になった頃から今までずっと社会から離れ、自宅にこもっているような状態が続いています。母は5年前に亡くなったのですが、それ以前から現在まで時、バイトなどをしているだけで、仕事が決まっても内容が合わなかったり、内定後、仕事先に行ってみると社内の雰囲気が悪かったりと長くは続かず、短期派遣を時折していました。しかし最近は、派遣の仕事さえも決まらず家にずっといるだけの状態になっています。父も高齢になってきており、一人っ子のため、先の事を考えると不安になります。友人も結婚したり、地方に引越したりと付き合いも無くなってきており、母の知人や派遣先で知り合った知人達とはメールでの連絡はとっていたのですが、最近はそんなメールも中止して欲しいと連絡してしまいました。親しくしていた母の親戚とも葬儀後、距離が出てしまい、父方の親戚とも連絡をとっていないため、先の事を考えると本当に不安です。こんな状況がずっと続いているのですが、今後、運命が変わる時は訪れるのでしょうか？鑑定結果はじめましてミミさん。占い師の翔生と申します。早速鑑定してみましょう。2007年の頃よりずっと、あなたは閉鎖的になってしまったようですね。これまでのあなたの努力は、誰にも真似できないほど頑張っていたに違いありません。お母様は深く感謝しておられます。お母様が今でもあなたに感謝しているのはあなたの努力あっての事とお察しします。その当時のあなたはとても精神的に辛く、肉体的にも疲れていた事でしょう。肉親との別れもあって、精神的に燃え尽きてしまった感触があります。その結果、誰かに意見されても、頑張ってきたという気持ちがあるせいか、周りの意見を遮断してしまいがちです。指図されたくない感情の方が優先されてしまうこれからの方向性にも、運勢上その傾向が見えてきています。確かにこれではまずい方向性にしか進めません。あなたが今一番、目標として手にしやすいものは、生活するための金銭を手にする事です。生活向上のためつまりはお金のためだけに頑張って働く事を目標にし、人付き合いに関しては遮断する方向でも現状では良いでしょう。まずは生活面の不安を少しでも緩和しない限り、人付き合いをする余裕は生まれません。周りの人の意見を聞く余裕ができた時は、あなたの運勢は向上します。お父様との生活がというより、あなたの日常の生活面で安定することを来年度の最優先の目標にしてください。恋愛に関しては全く考えていないようですが、心の余裕さえできれば二年以内に良縁という運勢も見えて来ています。全体的に人間関係において悲観的なあなたですが、ストレスが緩和されれば本来は人との付き合いが嫌いな方ではないと感じますので、あなたの思うほどあなたは周りから批難も否定もされません。むしろ、人付き合いの中でも、仕事でも、実欲を発揮しながら周りに認められ慕われるタイプです。来年はまずは、生活の安定を目標に頑張ってみませんか？応援しております。自分のために人生を送ることは悪いことではない人生というのは他人のものではない。自分のものだ。さんのためにということももちろん必要だが、自分のために努力し、時には優しくすることが重要である。自分に余裕が生まれることで、必然的に運命も良いものへと変わることができるだろう。nifty電話占いメール占い編集部翔生先生プロフィール亡くなった方との会話や可愛がっていた動物の魂との意思の疎通など、霊感による鑑定が得意。霊感による霊的存在との対話からあなたのこれから迎える環境人間関係などの状況を見通します。nifty電話占いメール占いでは霊感鑑定はもちろん、タロットから運勢の流れを読み解き、また、夢分析から近未来を予測します。関連サイトnifty電話占いメール占い翔生先生プロフィー\n",
      "Token IDs: tensor([    9,  3652,    26, 13508,    12, 19860,    57,  9123,    20,     7,\n",
      "         1393,  4221,  1429, 15133,   442,  4569,    20, 19133,  1272,     8,\n",
      "         5144,  2596,   612,  2855,  3244, 13426,    27,     8, 16058,  5448,\n",
      "          147,   318,   318,   774,   577,  1300,   559,    11,  4180,    12,\n",
      "        12079,  3413,   344,   229,  6741,  4294,   478, 20977, 10338,     7,\n",
      "          945,     7,  2416,    26, 27138,    12,  8988,  6671,  1068,  5176,\n",
      "        15710,  9146,     8,  2063,     7,  1226,  1743,  1589,   627,  6123,\n",
      "         6762,  6392,    30,  9527,  4550,     8,    80,   539,     7,     2])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = 80,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    \n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数：50\n",
      "検証データ数:　1690 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# データセットクラスの作成\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 90%地点のIDを取得\n",
    "#train_size = int(0.9 * len(dataset))\n",
    "#val_size = len(dataset) - train_size\n",
    "train_size = 50\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# データセットを分割\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数：{}'.format(train_size))\n",
    "print('検証データ数:　{} '.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "\n",
    "# 訓練データローダー\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "# 検証データローダー\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "len(validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dataloader\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcount = 128\n",
    "\n",
    "h_sentences = []\n",
    "t_sentences = []\n",
    "\n",
    "# wcount moji me kara kesu\n",
    "\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        h_sentences.append(sentences[i[0]][:wcount])\n",
    "    else:\n",
    "        h_sentences.append(sentences[i[0]])\n",
    "\n",
    "# ushiro kara wcount moji toru\n",
    "\n",
    "for i in enumerate(sentences):\n",
    "    if len(i[1])>wcount:\n",
    "        t_sentences.append(sentences[i[0]][-wcount:])\n",
    "    else:\n",
    "        t_sentences.append(sentences[i[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsentences = np.array(h_sentences)\n",
    "tsentences = np.array(t_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlNaKoNRBhuo"
   },
   "source": [
    "# BERT Tokenizerを用いて単語分割・IDへ変換\n",
    "## Tokenizerの準備\n",
    "単語分割とIDへ変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ueumK1gF-D2"
   },
   "source": [
    "# テスト実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1661699115434,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "9k0mj33mGD0I",
    "outputId": "9b3f3369-617c-4706-bbd7-7a9d1d0bb7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大単語数:  91\n",
      "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
     ]
    }
   ],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for sent in hsentences:\n",
    "    # Tokenizeで分割\n",
    "    h_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(h_token_words))\n",
    "for sent in tsentences:\n",
    "    # Tokenizeで分割\n",
    "    t_token_words = tokenizer.tokenize(sent)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(t_token_words))\n",
    "# 最大の値を確認\n",
    "print('最大単語数: ', max(max_len))\n",
    "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1661699115966,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "-xsginzEGHf5",
    "outputId": "6bf49efd-8a7d-452a-f16a-dd73d5f27b8b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  両親や親族が高齢なってくると、自分の人生を見つめ直さないといけないことがある。自分が独女の場合はなお更である。今回の相談者ミミさん女性38歳は母親が介護が必要になったことを機に働き方を変えたのだが、以降、仕事や人間関係がうまく築けずに悩み続けている。同時に\n",
      "Original:  霊的存在との対話からあなたのこれから迎える環境人間関係などの状況を見通します。nifty電話占いメール占いでは霊感鑑定はもちろん、タロットから運勢の流れを読み解き、また、夢分析から近未来を予測します。関連サイトnifty電話占いメール占い翔生先生プロフィー\n",
      "Token IDs: tensor([    9,  3652,    26, 13508,    12, 19860,    57,  9123,    20,     7,\n",
      "         1393,  4221,  1429, 15133,   442,  4569,    20, 19133,  1272,     8,\n",
      "         5144,  2596,   612,  2855,  3244, 13426,    27,     8, 16058,  5448,\n",
      "          147,   318,   318,   774,   577,  1300,   559,    11,  4180,    12,\n",
      "        12079,  3413,   344,   229,  6741,  4294,   478, 20977, 10338,     7,\n",
      "          945,     7,  2416,    26, 27138,    12,  8988,  6671,  1068,  5176,\n",
      "        15710,  9146,     8,  2063,     2,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n",
      "<class 'torch.Tensor'> tensor([0, 0, 0,  ..., 1, 1, 1])\n",
      "torch.Size([1740, 130])\n",
      "torch.Size([1740, 130])\n",
      "torch.Size([1740])\n",
      "1740\n"
     ]
    }
   ],
   "source": [
    "h_input_ids = []\n",
    "t_input_ids = []\n",
    "h_attention_masks = []\n",
    "t_attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for sent in hsentences:\n",
    "    hencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # print(hencoded_dict)\n",
    "\n",
    "    h_input_ids.append(hencoded_dict['input_ids'])\n",
    "    h_attention_masks.append(hencoded_dict['attention_mask'])\n",
    "    \n",
    "for sent in tsentences:\n",
    "    tencoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = wcount+2,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    t_input_ids.append(tencoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    t_attention_masks.append(tencoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "h_input_ids = torch.cat(h_input_ids, dim=0)\n",
    "t_input_ids = torch.cat(t_input_ids, dim=0)\n",
    "h_attention_masks = torch.cat(h_attention_masks, dim=0)\n",
    "t_attention_masks = torch.cat(t_attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', hsentences[0])\n",
    "print('Original: ', tsentences[0])\n",
    "print('Token IDs:', h_input_ids[0])\n",
    "print(type(labels), labels)\n",
    "print(torch.Tensor.size(h_input_ids))\n",
    "print(torch.Tensor.size(h_attention_masks))\n",
    "print(torch.Tensor.size(labels))\n",
    "print(hsentences.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    9,  3652,    26,  ...,     3,     3,     3],\n",
       "        [    9,  3911,    10,  ...,     3,     3,     3],\n",
       "        [    9,  1743, 26243,  ...,     3,     3,     3],\n",
       "        ...,\n",
       "        [    9,  1387,  1773,  ...,     3,     3,     3],\n",
       "        [ 3502, 12393,    26,  ...,     3,     3,     3],\n",
       "        [  673,   223,  5874,  ...,     3,     3,     3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1661699115968,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "uX3Hz3YNGKhH",
    "outputId": "bcba9374-dc24-4067-f46c-fa3d6343511c"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torchvision import transforms, datasets\n",
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "# データセットクラスの作成\n",
    "# dataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "hdataset = TensorDataset(h_input_ids, h_attention_masks, labels)\n",
    "tdataset = TensorDataset(t_input_ids, t_attention_masks, labels)\n",
    "# dataset = CustomTensorDataset(tensors = (input_ids, labels), transform = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数：50\n",
      "検証データ数:　1690 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[    9,  1387,  1773,  ...,     3,     3,     3],\n",
       "         [    9, 12096,    33,  ...,     3,     3,     3],\n",
       "         [    9, 14193,    31,  ...,     3,     3,     3],\n",
       "         ...,\n",
       "         [    9, 13339,  2874,  ...,     3,     3,     3],\n",
       "         [   77,  1583,  4473,  ...,     3,     3,     3],\n",
       "         [    9,  8669,     7,  ...,     3,     3,     3]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "         1, 1, 0, 1, 0, 0, 1, 0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80%地点のIDを取得\n",
    "num_dataset = len(hdataset)\n",
    "#train_size = int(0.1 * num_dataset)\n",
    "#val_size = num_dataset - train_size\n",
    "\n",
    "train_size = 50\n",
    "val_size = len(hdataset) - train_size\n",
    "\n",
    "# データセhttp://localhost:8888/notebooks/bert-zuco/augmentation/BERTclassification-mydata-local-augmentation-aug.ipynb#ットを分割\n",
    "h_train_dataset, h_val_dataset = random_split(hdataset, [train_size, val_size])\n",
    "t_train_dataset, t_val_dataset = random_split(tdataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数：{}'.format(train_size))\n",
    "print('検証データ数:　{} '.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    synreplace(1),\n",
    "    randinsert(3),\n",
    "    randdelete(0.15), \n",
    "    randswap(2)\n",
    "])\n",
    "\n",
    "\n",
    "class MySubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xa, mask, label = self.dataset[self.indices[idx]]\n",
    "        if self.transform:\n",
    "            xa = self.transform(xa)\n",
    "        return xa, mask, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "indices = np.random.choice(num_dataset, num_dataset, replace=False)\n",
    "\n",
    "h_train_dataset = MySubset(hdataset, indices[:train_size], data_transform)\n",
    "h_val_dataset = MySubset(hdataset, indices[train_size:])\n",
    "t_train_dataset = MySubset(tdataset, indices[:train_size], data_transform)\n",
    "t_val_dataset = MySubset(tdataset, indices[train_size:])\n",
    "\n",
    "\n",
    "\n",
    "# 訓練データローダー\n",
    "h_train_dataloader = DataLoader(\n",
    "            h_train_dataset,  \n",
    "            sampler = RandomSampler(h_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "t_train_dataloader = DataLoader(\n",
    "            t_train_dataset,\n",
    "            sampler = RandomSampler(t_train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# 検証データローダー\n",
    "h_validation_dataloader = DataLoader(\n",
    "            h_val_dataset, \n",
    "            sampler = SequentialSampler(h_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "t_validation_dataloader = DataLoader(\n",
    "            t_val_dataset, \n",
    "            sampler = SequentialSampler(t_val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "\n",
    "hoge = h_validation_dataloader.__iter__()\n",
    "hoge.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f7a30861460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    with open('headmodel.pickle', mode='rb') as fp:\\n    Hmodel = pickle.load(fp)\\nwith open('tailmodel.pickle', mode='rb') as fp:\\n    Tmodel = pickle.load(fp)\\nwith open('summarymodel.pickle', mode='rb') as fp:\\n    Smodel = pickle.load(fp)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('LGBMmodel.pickle', mode='rb') as fp:\n",
    "    Lmodel = pickle.load(fp)\n",
    "'''\n",
    "    with open('headmodel.pickle', mode='rb') as fp:\n",
    "    Hmodel = pickle.load(fp)\n",
    "with open('tailmodel.pickle', mode='rb') as fp:\n",
    "    Tmodel = pickle.load(fp)\n",
    "with open('summarymodel.pickle', mode='rb') as fp:\n",
    "    Smodel = pickle.load(fp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lmodel.predict(train_dataset)  koreugokannte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9929328cf8d246d2b5be77a5fca18c0f",
      "7ce3a9778e6841e38f6bb2c3d8cfe9b8",
      "8988d5fad2d14b9b97cd311e99093641",
      "e72ccacac3434f939cd0e4adfb3bcc4d",
      "a9503913e9204c7994b76af2f3fd7d3a",
      "105e552bd7bd468f976e099cbe7c74cf",
      "fe1020e5f4eb483fa3fce57764a2508c",
      "9bb08df9e5004f5da8678c2fd10c8eb2",
      "887ca9f3ec9247c4b402bc72745aad0d",
      "50d37681841a449094298dcb52ff9059",
      "9f37d02a0ba944dc9633a68d71891f87",
      "a93d3d99fab445ea80248bd9ae7b0d60",
      "fa68d1e07ae94cd2824d767335a63c64",
      "f69e8de282434b9aa8a457a73593d080",
      "1ed1c48157da42b7bc8719879f3c13c8",
      "7093eae4a1e94e7fbc341564be6a727c",
      "e13d9164a1a6418b87f8fc9f2f5d10eb",
      "c7b849cdaf324e108283b9930d31ec7e",
      "a6e9829602e047f5ab93e3dfb66195cb",
      "baa09b17fcba4d8593e8155907a72c31",
      "7481c5bc470c42cf8ef6d38b69c4ce8a",
      "240f4e1960d44c189adf177c9eb4a17e"
     ]
    },
    "executionInfo": {
     "elapsed": 28456,
     "status": "ok",
     "timestamp": 1661699144410,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "tXUhEdWTGPRs",
    "outputId": "f525692a-ffa0-49cf-a54c-0f91707721b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 18:27:48.575143: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 18:27:48.801596: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-04 18:27:49.318230: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-04 18:27:49.318285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-04 18:27:49.318291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "h_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinaryなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "t_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinaryなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "# モデルをGPUへ転送\n",
    "h_model.cuda()\n",
    "t_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1661699144412,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "cq-TvSWHJrQS",
    "outputId": "4a256f4d-c7cc-4ee4-98ae-cc2ca7b6d597"
   },
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = AdamW(h_model.parameters(), lr=2e-5)\n",
    "optimizer = AdamW(t_model.parameters(), lr=2e-5)\n",
    "\n",
    "# 訓練パートの定義\n",
    "def h_train(h_model):\n",
    "    h_model.train() # 訓練モードで実行\n",
    "    h_train_loss = 0\n",
    "    for batch in h_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = h_model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(h_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        h_train_loss += loss.item()\n",
    "    return h_train_loss\n",
    "\n",
    "def t_train(t_model):\n",
    "    t_model.train() # 訓練モードで実行\n",
    "    t_train_loss = 0\n",
    "    for batch in t_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = t_model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(t_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        t_train_loss += loss.item()\n",
    "    return t_train_loss\n",
    "\n",
    "# テストパートの定義\n",
    "def h_validation(h_model):\n",
    "    h_model.eval()# 訓練モードをオフ\n",
    "    h_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in h_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = h_model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            h_val_loss += loss.item()\n",
    "    return h_val_loss\n",
    "\n",
    "def t_validation(t_model):\n",
    "    t_model.eval()# 訓練モードをオフ\n",
    "    t_val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in t_validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = t_model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            t_val_loss += loss.item()\n",
    "    return t_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPwWkV3HJtaG"
   },
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "max_epoch = 50\n",
    "t_train_loss_ = []\n",
    "t_test_loss_ = []\n",
    "h_train_loss_ = []\n",
    "h_test_loss_ = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    h_train_ = h_train(h_model)\n",
    "    h_test_ = h_train(h_model)\n",
    "    h_train_loss_.append(h_train_)\n",
    "    h_test_loss_.append(h_test_)\n",
    "    t_train_ = t_train(t_model)\n",
    "    t_test_ = t_train(t_model)\n",
    "    t_train_loss_.append(t_train_)\n",
    "    t_test_loss_.append(t_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_input_mask.size(), b_input_ids.size(), labels.size()\n",
    "# outputs = self.model(torch.unsqueeze(token_tensor, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_model.train() # 訓練モードで実行\n",
    "t_model.train() # 訓練モードで実行\n",
    "h_train_loss = 0\n",
    "t_train_loss = 0\n",
    "for batch in h_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = h_model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    h_loss = outputs.loss\n",
    "    h_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(h_model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    h_train_loss += h_loss.item()\n",
    "\n",
    "for batch in t_train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "#    b_input_ids = batch[0].to(device)\n",
    "#    b_input_mask = batch[1].to(device)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = torch.t(batch[2]).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = t_model(b_input_ids, \n",
    "                         token_type_ids=None, \n",
    "                         attention_mask=b_input_mask, \n",
    "                         labels=b_labels)\n",
    "    t_loss = outputs.loss\n",
    "    t_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(t_model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    t_train_loss += t_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tyD6cO4JvJa"
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "#correct = 0\n",
    "h_test_accuracy = []\n",
    "t_test_accuracy = []\n",
    "\n",
    "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
    "\n",
    "h_model.eval()# 訓練モードをオフ\n",
    "t_model.eval()# 訓練モードをオフ\n",
    "\n",
    "for batch in h_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        h_preds = h_model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        h_test_accuracy.append((torch.argmax(h_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "for batch in t_validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        t_preds = t_model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        t_test_accuracy.append((torch.argmax(t_preds[0], 1) == b_labels).sum().item() / len(b_labels))\n",
    "\n",
    "        #print('preds: ', torch.argmax(preds[0], 1))\n",
    "        #print('b_labels: ', b_labels)\n",
    "'''\n",
    "        if preds == b_labels:\n",
    "            correct += 1\n",
    "            #test_accuracy += torch.sum(preds == b_labels).item() / len(b_labels)\n",
    "\n",
    "#test_accuracy = correct/len(b_labels)\n",
    "print(correct)\n",
    "'''\n",
    "print(statistics.mean(h_test_accuracy))\n",
    "print(statistics.mean(t_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pred_df = pd.DataFrame(np.argmax(h_preds[0].cpu().numpy(), axis=1), columns=['h_pred_label'])\n",
    "t_pred_df = pd.DataFrame(np.argmax(t_preds[0].cpu().numpy(), axis=1), columns=['t_pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([h_pred_df, t_pred_df, label_df], axis=1)\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4, 4)\n",
    "print(a)\n",
    "print(torch.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1661699237395,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "pHF_S3-tJx9i",
    "outputId": "763f4858-5255-4ddf-ade2-0b67dd0d5b75"
   },
   "outputs": [],
   "source": [
    "# 予測結果の確認\n",
    "print(f'出力:{h_preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1661699237396,
     "user": {
      "displayName": "西梓",
      "userId": "09370432736438252128"
     },
     "user_tz": -540
    },
    "id": "5JCSY_YpJ0Qm",
    "outputId": "624497aa-500a-478b-c8fe-0727efee504a"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# 比較しやすい様にpd.dataframeへ整形\n",
    "import numpy as np\n",
    "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
    "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
    "## np.argmaxで大き方の値を取得\n",
    "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
    "accuracy_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "correct = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "p_list = []\n",
    "l_list = []\n",
    "\n",
    "p_list = pred_df.values.tolist()\n",
    "l_list = label_df.values.tolist()\n",
    "\n",
    "#print(type(pred_df))\n",
    "\n",
    "for i in range(len(b_labels)):\n",
    "    if(p_list[i] == l_list[i]):\n",
    "        correct += 1\n",
    "\n",
    "test_accuracy = correct/len(b_labels)\n",
    "\n",
    "print(test_accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(h_test_loss_)), h_test_loss_, label=\"Head\")\n",
    "plt.plot(range(len(t_test_loss_)), t_test_loss_, label=\"Tail\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()  # ラベルがあるときは、きちんとplt.show()を呼び出すこと"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERTclassification.ipynb",
   "provenance": [
    {
     "file_id": "1mxMTVW123hMPhZLg9UjVEhkL_vrFvMp7",
     "timestamp": 1659890794413
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08a0764a15bb4b45ab9bfdbe3a02c318": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b407dd3170f4f55be7f8708c59d262b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5616789e354d45699ea2040757dbd5c3",
       "IPY_MODEL_d6bc8aac6ca74bff92bba66f17c20b00",
       "IPY_MODEL_96fb1e06ef4349b5b6a071be230a711c"
      ],
      "layout": "IPY_MODEL_8d05e54e5fc644d2a3c974758c5e439c"
     }
    },
    "105e552bd7bd468f976e099cbe7c74cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11cc64e4ce0843ae88a651762d68b844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1aff4434a10549e387f749140d4721f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ed1c48157da42b7bc8719879f3c13c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7481c5bc470c42cf8ef6d38b69c4ce8a",
      "placeholder": "​",
      "style": "IPY_MODEL_240f4e1960d44c189adf177c9eb4a17e",
      "value": " 424M/424M [00:15&lt;00:00, 54.9MB/s]"
     }
    },
    "240f4e1960d44c189adf177c9eb4a17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dc2139703bb4448969390f2a91e00f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994b8f69c284d758c5f04deeb3fcca1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "423c0b6849204bbc96c7b039633373f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4535f833bfac4540a8add9686f623b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9279616c547b47de92a436ebb026fd79",
      "max": 153,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3910389daf34e31af5f33ef7d539625",
      "value": 153
     }
    },
    "45555846fc9746af9a06d76c6c9aee1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46351ebb1bfd41b5b9fbc4de40e218e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50d37681841a449094298dcb52ff9059": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5616789e354d45699ea2040757dbd5c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a20acb0a8fc4320af5a849c9d780649",
      "placeholder": "​",
      "style": "IPY_MODEL_45555846fc9746af9a06d76c6c9aee1b",
      "value": "Downloading spiece.model: 100%"
     }
    },
    "705cf2ba17614d51853eeb9dfc74d540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3994b8f69c284d758c5f04deeb3fcca1",
      "max": 259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_08a0764a15bb4b45ab9bfdbe3a02c318",
      "value": 259
     }
    },
    "7093eae4a1e94e7fbc341564be6a727c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73fb8df2799443d996d165878dc526a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9f368ede2d24e3095242e9a3cf8c545",
       "IPY_MODEL_4535f833bfac4540a8add9686f623b54",
       "IPY_MODEL_7803695cfa5742bf85208ee04193acb0"
      ],
      "layout": "IPY_MODEL_423c0b6849204bbc96c7b039633373f9"
     }
    },
    "7481c5bc470c42cf8ef6d38b69c4ce8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7803695cfa5742bf85208ee04193acb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d808ec79b0dd465a82077ca7f2c8feb6",
      "placeholder": "​",
      "style": "IPY_MODEL_d2a46f9221b14f86a3330510812f258e",
      "value": " 153/153 [00:00&lt;00:00, 4.82kB/s]"
     }
    },
    "7ce3a9778e6841e38f6bb2c3d8cfe9b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_105e552bd7bd468f976e099cbe7c74cf",
      "placeholder": "​",
      "style": "IPY_MODEL_fe1020e5f4eb483fa3fce57764a2508c",
      "value": "Downloading config.json: 100%"
     }
    },
    "83cf06c42be34c068dbbf6fcc5cfd6d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f629f372d73b44efb31e8d7c5a45d4cd",
      "placeholder": "​",
      "style": "IPY_MODEL_93c25b4c96e64fecbb7f569527e50722",
      "value": " 259/259 [00:00&lt;00:00, 8.26kB/s]"
     }
    },
    "887ca9f3ec9247c4b402bc72745aad0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8988d5fad2d14b9b97cd311e99093641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bb08df9e5004f5da8678c2fd10c8eb2",
      "max": 479,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_887ca9f3ec9247c4b402bc72745aad0d",
      "value": 479
     }
    },
    "8d05e54e5fc644d2a3c974758c5e439c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9279616c547b47de92a436ebb026fd79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "937dd0c1d06e4d69824b7be991cc52f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c25b4c96e64fecbb7f569527e50722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96fb1e06ef4349b5b6a071be230a711c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd4beed83d947b9a5eec5918dcd2319",
      "placeholder": "​",
      "style": "IPY_MODEL_1aff4434a10549e387f749140d4721f4",
      "value": " 787k/787k [00:00&lt;00:00, 11.4MB/s]"
     }
    },
    "9929328cf8d246d2b5be77a5fca18c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ce3a9778e6841e38f6bb2c3d8cfe9b8",
       "IPY_MODEL_8988d5fad2d14b9b97cd311e99093641",
       "IPY_MODEL_e72ccacac3434f939cd0e4adfb3bcc4d"
      ],
      "layout": "IPY_MODEL_a9503913e9204c7994b76af2f3fd7d3a"
     }
    },
    "9a20acb0a8fc4320af5a849c9d780649": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a9b67b9ebf94a13a95e759a696c884f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bb08df9e5004f5da8678c2fd10c8eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f37d02a0ba944dc9633a68d71891f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0880f15772d4156a9eb94d6314c2d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e9829602e047f5ab93e3dfb66195cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93d3d99fab445ea80248bd9ae7b0d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa68d1e07ae94cd2824d767335a63c64",
       "IPY_MODEL_f69e8de282434b9aa8a457a73593d080",
       "IPY_MODEL_1ed1c48157da42b7bc8719879f3c13c8"
      ],
      "layout": "IPY_MODEL_7093eae4a1e94e7fbc341564be6a727c"
     }
    },
    "a9503913e9204c7994b76af2f3fd7d3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3910389daf34e31af5f33ef7d539625": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baa09b17fcba4d8593e8155907a72c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7b849cdaf324e108283b9930d31ec7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f368ede2d24e3095242e9a3cf8c545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_937dd0c1d06e4d69824b7be991cc52f0",
      "placeholder": "​",
      "style": "IPY_MODEL_11cc64e4ce0843ae88a651762d68b844",
      "value": "Downloading special_tokens_map.json: 100%"
     }
    },
    "cfd1b9e85db447fbaf01f66f6f0f6429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dc2139703bb4448969390f2a91e00f6",
      "placeholder": "​",
      "style": "IPY_MODEL_46351ebb1bfd41b5b9fbc4de40e218e3",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "d2a46f9221b14f86a3330510812f258e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d337eb6795e241389d9b35805a59fc22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6bc8aac6ca74bff92bba66f17c20b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0880f15772d4156a9eb94d6314c2d9e",
      "max": 805634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d337eb6795e241389d9b35805a59fc22",
      "value": 805634
     }
    },
    "d808ec79b0dd465a82077ca7f2c8feb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd6aadfe79224713b5a47dd108ff71b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfd1b9e85db447fbaf01f66f6f0f6429",
       "IPY_MODEL_705cf2ba17614d51853eeb9dfc74d540",
       "IPY_MODEL_83cf06c42be34c068dbbf6fcc5cfd6d5"
      ],
      "layout": "IPY_MODEL_9a9b67b9ebf94a13a95e759a696c884f"
     }
    },
    "e13d9164a1a6418b87f8fc9f2f5d10eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e72ccacac3434f939cd0e4adfb3bcc4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50d37681841a449094298dcb52ff9059",
      "placeholder": "​",
      "style": "IPY_MODEL_9f37d02a0ba944dc9633a68d71891f87",
      "value": " 479/479 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "efd4beed83d947b9a5eec5918dcd2319": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f629f372d73b44efb31e8d7c5a45d4cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f69e8de282434b9aa8a457a73593d080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6e9829602e047f5ab93e3dfb66195cb",
      "max": 445021143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baa09b17fcba4d8593e8155907a72c31",
      "value": 445021143
     }
    },
    "fa68d1e07ae94cd2824d767335a63c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e13d9164a1a6418b87f8fc9f2f5d10eb",
      "placeholder": "​",
      "style": "IPY_MODEL_c7b849cdaf324e108283b9930d31ec7e",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "fe1020e5f4eb483fa3fce57764a2508c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
