{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d2ae95",
   "metadata": {},
   "source": [
    "https://tech.yellowback.net/posts/sentence-transformers-japanese-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d7ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset stsb_multi_mt_ja (/home/azusa/.cache/huggingface/datasets/stsb_multi_mt_ja/ja/1.0.0/4dd9064b972654378b649a76e3ca8371dcd15f09653d562d173190586f1a4fd0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset('stsb_multi_mt_ja', 'ja', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb856df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from datasets import load_dataset\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Limit torch to 4 threads\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    model_name = sys.argv[1]\n",
    "else:\n",
    "    model_name = 'sentence-transformers/stsb-xlm-r-multilingual'\n",
    "\n",
    "ds = load_dataset('stsb_multi_mt_ja', 'ja', split='test')\n",
    "#ds_en = load_dataset('stsb_multi_mt_ja', 'en', split='test')\n",
    "\n",
    "sentences1 = ds['sentence1']\n",
    "scores = [x/5.0 for x in ds['similarity_score']]\n",
    "sentences2 = ds['sentence2']\n",
    "#sentences2 = ds_en['sentence2']\n",
    "\n",
    "print(sentences1[:3], sentences2[:3])\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1,\n",
    "    sentences2,\n",
    "    scores,\n",
    "    main_similarity=SimilarityFunction.COSINE)\n",
    "model.evaluate(evaluator)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ed4389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 23:16:42 - Reusing dataset stsb_multi_mt_ja (/home/azusa/.cache/huggingface/datasets/stsb_multi_mt_ja/ja/1.0.0/4dd9064b972654378b649a76e3ca8371dcd15f09653d562d173190586f1a4fd0)\n",
      "['女の子が髪をスタイリングしています。', '海辺でサッカーをしている男性グループ。', '一人の女性が別の女性の足首を測っている。'] ['少女が髪をとかしている。', '海辺でサッカーをしている男の子たちのグループ。', '女性が他の女性の足首を測る。']\n",
      "-f\n",
      "2022-09-22 23:16:42 - Load pretrained SentenceTransformer: -f\n"
     ]
    },
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "404 Client Error: Repository Not Found for url: https://huggingface.co/api/models/sentence-transformers/-f. If the repo is private, make sure you are authenticated. (Request ID: EjNazgmc8dgkieYlmnxDt)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[0;32m---> 39\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m EmbeddingSimilarityEvaluator(sentences1, sentences2, scores, main_similarity\u001b[38;5;241m=\u001b[39mSimilarityFunction\u001b[38;5;241m.\u001b[39mCOSINE, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msts-test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m     spearman_cos \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(evaluator)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:81\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder)\u001b[0m\n\u001b[1;32m     77\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;66;03m# Download from hub\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m         model_path_tmp \u001b[38;5;241m=\u001b[39m \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mignore_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflax_model.msgpack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrust_model.ot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m         os\u001b[38;5;241m.\u001b[39mrename(model_path_tmp, model_path)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.9/site-packages/sentence_transformers/util.py:398\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files)\u001b[0m\n\u001b[1;32m    395\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cache_dir)\n\u001b[1;32m    397\u001b[0m _api \u001b[38;5;241m=\u001b[39m HfApi()\n\u001b[0;32m--> 398\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m storage_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    401\u001b[0m     cache_dir, repo_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, REPO_ID_SEPARATOR) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_info\u001b[38;5;241m.\u001b[39msha\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_file \u001b[38;5;129;01min\u001b[39;00m model_info\u001b[38;5;241m.\u001b[39msiblings:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.9/site-packages/huggingface_hub/hf_api.py:1136\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, token, timeout, securityStatus)\u001b[0m\n\u001b[1;32m   1132\u001b[0m status_query_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecurityStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m} \u001b[38;5;28;01mif\u001b[39;00m securityStatus \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1134\u001b[0m     path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mstatus_query_param\n\u001b[1;32m   1135\u001b[0m )\n\u001b[0;32m-> 1136\u001b[0m \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.9/site-packages/huggingface_hub/utils/_errors.py:60\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m     58\u001b[0m error_code \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Error-Code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m404 Client Error: Repository Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m repo is private, make sure you are authenticated. (Request ID:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevisionNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RevisionNotFoundError(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m404 Client Error: Revision Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (Request\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error: Repository Not Found for url: https://huggingface.co/api/models/sentence-transformers/-f. If the repo is private, make sure you are authenticated. (Request ID: EjNazgmc8dgkieYlmnxDt)"
     ]
    }
   ],
   "source": [
    "#Limit torch to 4 threads\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "models = [\n",
    "    'sentence-transformers/LaBSE',\n",
    "    'xlm-roberta-base',\n",
    "    'xlm-roberta-large',\n",
    "    'sentence-transformers/quora-distilbert-multilingual',\n",
    "    'sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking',\n",
    "    'sentence-transformers/distiluse-base-multilingual-cased-v2',\n",
    "    'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    "    'sentence-transformers/paraphrase-xlm-r-multilingual-v1',\n",
    "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'sentence-transformers/stsb-xlm-r-multilingual',\n",
    "]\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    models = sys.argv[1:]\n",
    "\n",
    "ds = load_dataset('stsb_multi_mt_ja', 'ja', split='test')\n",
    "\n",
    "sentences1 = ds['sentence1']\n",
    "sentences2 = ds['sentence2']\n",
    "scores = [x/5.0 for x in ds['similarity_score']]\n",
    "\n",
    "print(sentences1[:3], sentences2[:3])\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name in models:\n",
    "    print(model_name)\n",
    "    model = SentenceTransformer(model_name)\n",
    "    evaluator = EmbeddingSimilarityEvaluator(sentences1, sentences2, scores, main_similarity=SimilarityFunction.COSINE, name='sts-test')\n",
    "    spearman_cos = model.evaluate(evaluator)\n",
    "    results.append('| {:s} | {:.1f} |'.format(model_name, spearman_cos * 100))\n",
    "\n",
    "print('| model | spearman_cos |')\n",
    "print('|-------|-------------:|')\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
