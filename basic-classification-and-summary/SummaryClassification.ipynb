{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637feaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: filelock in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: sacremoses in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: six in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!apt install swig\n",
    "# Sentencepieceのインストール\n",
    "!pip install sentencepiece\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10781bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (1.11.0)\r\n",
      "Requirement already satisfied: typing_extensions in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torch) (4.3.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b527e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41cb2c",
   "metadata": {},
   "source": [
    "## data shori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21819e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = '/export/livedoor' \n",
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|※|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|：|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c66a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/it-life-hack']\n",
    "target_genre = [\"dokujo-tsushin\", \"it-life-hack\"] \n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "        #if os.path.isfile(f):\n",
    "        #    print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357bffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1740, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>意外と身近にあるレアアースを知</td>\n",
       "      <td>昨年、中国がレアアースの輸出規制をして以来、レアアース問題に世間の関心は集まっている。ところ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>オトナ女子映画部愛されるより愛す喜びに生きるエディットピアフ愛の讃</td>\n",
       "      <td>女性へのメッセージをいただけますか？愛しなさい若い子には？愛しなさい子供には？愛しなさいラス...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>ジメっとした気分を吹き飛ばせ！いまが見ごろ、鎌倉の紫陽花写真の</td>\n",
       "      <td>この季節の代表的な花と言えば紫陽花だ。土壌の状態ph度で花の色が変わり酸性なら青アルカリ性な...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>昔、不幸の手紙は今やチェーンメー</td>\n",
       "      <td>かつて不幸の手紙なるものがあった。ネットのない時代だったので、葉書にこの手紙を人に送らないと...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>災害ボランティア体験者が感じたこ</td>\n",
       "      <td>東日本大震災から、約２ヵ月。TVで流れてくる映像やネットから伝わる情報に衝撃を受け、何も手に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>2D動画を3Dに変換！Webから動画ダウンロードもできるソフトのレビューアー募集開</td>\n",
       "      <td>ソーシャルレビューコミュニティzigsowジグソーは、Wondershare社ワンダーシェア...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>お寿司orステーキ！？デートでは何が食べたい</td>\n",
       "      <td>7歳年上の自営業の男性と見合いをした歩さん29歳。相手は写真より実物のほうが素敵な人だったし...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>Windows＆LinuxのデュアルOS！ThinkpadX1Hybrid39より発売開始</td>\n",
       "      <td>1月のCESでアナウンスされ、試作段階とは思えない完成度の高さ、日本発！大和研究所魂で多くの...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>マスクで顔を隠す独女た</td>\n",
       "      <td>東京渋谷のセンター街でマスク姿の1030代の男女100人にアンケート調査を実施したところ、男...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>it-life-hack</td>\n",
       "      <td>1</td>\n",
       "      <td>ダウンロードカードも販売！任天堂によるソフトダウンロード販売の詳細が明らかにデジ</td>\n",
       "      <td>任天堂はいままではパッケージソフトの販売は、ゲーム販売店や大手量販店で販売する方法が主流だっ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          media_name  label                                          title  \\\n",
       "328   dokujo-tsushin      0                                意外と身近にあるレアアースを知   \n",
       "639   dokujo-tsushin      0              オトナ女子映画部愛されるより愛す喜びに生きるエディットピアフ愛の讃   \n",
       "1477    it-life-hack      1                ジメっとした気分を吹き飛ばせ！いまが見ごろ、鎌倉の紫陽花写真の   \n",
       "309   dokujo-tsushin      0                               昔、不幸の手紙は今やチェーンメー   \n",
       "341   dokujo-tsushin      0                               災害ボランティア体験者が感じたこ   \n",
       "1396    it-life-hack      1      2D動画を3Dに変換！Webから動画ダウンロードもできるソフトのレビューアー募集開   \n",
       "624   dokujo-tsushin      0                         お寿司orステーキ！？デートでは何が食べたい   \n",
       "1038    it-life-hack      1  Windows＆LinuxのデュアルOS！ThinkpadX1Hybrid39より発売開始   \n",
       "385   dokujo-tsushin      0                                    マスクで顔を隠す独女た   \n",
       "1702    it-life-hack      1       ダウンロードカードも販売！任天堂によるソフトダウンロード販売の詳細が明らかにデジ   \n",
       "\n",
       "                                               sentence  \n",
       "328   昨年、中国がレアアースの輸出規制をして以来、レアアース問題に世間の関心は集まっている。ところ...  \n",
       "639   女性へのメッセージをいただけますか？愛しなさい若い子には？愛しなさい子供には？愛しなさいラス...  \n",
       "1477  この季節の代表的な花と言えば紫陽花だ。土壌の状態ph度で花の色が変わり酸性なら青アルカリ性な...  \n",
       "309   かつて不幸の手紙なるものがあった。ネットのない時代だったので、葉書にこの手紙を人に送らないと...  \n",
       "341   東日本大震災から、約２ヵ月。TVで流れてくる映像やネットから伝わる情報に衝撃を受け、何も手に...  \n",
       "1396  ソーシャルレビューコミュニティzigsowジグソーは、Wondershare社ワンダーシェア...  \n",
       "624   7歳年上の自営業の男性と見合いをした歩さん29歳。相手は写真より実物のほうが素敵な人だったし...  \n",
       "1038  1月のCESでアナウンスされ、試作段階とは思えない完成度の高さ、日本発！大和研究所魂で多くの...  \n",
       "385   東京渋谷のセンター街でマスク姿の1030代の男女100人にアンケート調査を実施したところ、男...  \n",
       "1702  任天堂はいままではパッケージソフトの販売は、ゲーム販売店や大手量販店で販売する方法が主流だっ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "# データの確認\n",
    "print(f'データサイズ： {df.shape}')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51fb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df.media_name.values\n",
    "labels = df.label.values\n",
    "titles = df.title.values\n",
    "sentences = df.sentence.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb6684",
   "metadata": {},
   "source": [
    "## moderu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658f021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_s = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer_s = AutoTokenizer.from_pretrained(model_name_s)\n",
    "model_s = AutoModelForSeq2SeqLM.from_pretrained(model_name_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9c301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = np.zeros(len(sentences), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9507d3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    article_text = sentences[i]\n",
    "    input_ids = tokenizer_s(\n",
    "        article_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=6000\n",
    "    )[\"input_ids\"]\n",
    "    output_ids = model_s.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=1024,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_beams=4\n",
    "    )[0]\n",
    "    summary = tokenizer_s.decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    summaries[i] = summary\n",
    "    if i % 10 == 0:\n",
    "        print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b692b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summas = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    summas.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(summaries[i])))\n",
    "\n",
    "summas = pd.DataFrame(summas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1a6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大単語数:  68\n",
      "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
     ]
    }
   ],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    # Tokenizeで分割\n",
    "    token_words = tokenizer.tokenize(summa)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(token_words))\n",
    "# 最大の値を確認\n",
    "print('最大単語数: ', max(max_len))\n",
    "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "777b2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  思いがけないことがある人間は、未来を教えてくれることがある。\n",
      "Token IDs: tensor([    9,  2969,    12, 18143,  1272,   858,    11,     7,  3638, 15718,\n",
      "        17379,  1272,     8,     2,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        summa,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = 50,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    \n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', summaries[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d99dbcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数：1566\n",
      "検証データ数:　174 \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# データセットクラスの作成\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 90%地点のIDを取得\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# データセットを分割\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数：{}'.format(train_size))\n",
    "print('検証データ数:　{} '.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "\n",
    "# 訓練データローダー\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "# 検証データローダー\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9fdb391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "# モデルをGPUへ転送\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8681226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 訓練パートの定義\n",
    "def train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss\n",
    "\n",
    "# テストパートの定義\n",
    "def validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ebb09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "max_epoch = 10\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train_ = train(model)\n",
    "    test_ = train(model)\n",
    "    train_loss_.append(train_)\n",
    "    test_loss_.append(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7e4159",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 検証方法の確認（1バッチ分で計算ロジックに確認）\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\u001b[38;5;66;03m# 訓練モードをオフ\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m validation_dataloader:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#print(batch)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     b_input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#correct = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
    "\n",
    "model.eval()# 訓練モードをオフ\n",
    "for batch in validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        test_accuracy += (torch.argmax(preds[0]) == b_labels).sum().item() / len(b_labels)\n",
    "\n",
    "        #print(preds[0])\n",
    "        #print(b_labels)\n",
    "\n",
    "print(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b92e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力:SequenceClassifierOutput(loss=None, logits=tensor([[ 1.2220, -1.5854],\n",
      "        [ 1.2220, -1.5854],\n",
      "        [ 4.9110, -4.4560],\n",
      "        [-5.0631,  4.7583],\n",
      "        [-4.9945,  4.5908],\n",
      "        [-5.1711,  4.8990],\n",
      "        [-5.1092,  4.8347],\n",
      "        [-5.0992,  4.8399],\n",
      "        [-5.1289,  4.7986],\n",
      "        [-5.1814,  4.7742],\n",
      "        [-4.7300,  4.3734],\n",
      "        [ 4.8924, -4.2957],\n",
      "        [ 4.8416, -4.4289],\n",
      "        [-5.0318,  4.6252]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の確認\n",
    "print(f'出力:{preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7425ef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_0</th>\n",
       "      <th>logit_1</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.221978</td>\n",
       "      <td>-1.585371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.221978</td>\n",
       "      <td>-1.585371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.910961</td>\n",
       "      <td>-4.456045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.063131</td>\n",
       "      <td>4.758265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.994461</td>\n",
       "      <td>4.590831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logit_0   logit_1  pred_label  true_label\n",
       "0  1.221978 -1.585371           0           0\n",
       "1  1.221978 -1.585371           0           0\n",
       "2  4.910961 -4.456045           0           0\n",
       "3 -5.063131  4.758265           1           1\n",
       "4 -4.994461  4.590831           1           1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比較しやすい様にpd.dataframeへ整形\n",
    "import numpy as np\n",
    "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
    "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
    "## np.argmaxで大き方の値を取得\n",
    "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5680f066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_loss_)), train_loss_, label=\"Train\")\n",
    "plt.plot(range(len(test_loss_)), test_loss_, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()  # ラベルがあるときは、きちんとplt.show()を呼び出すこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e7deb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "summary_set = \"summary_set_dokujo_it.tsv\" \n",
    "\n",
    "if os.path.exists(summary_set) == True:\n",
    "    with open(summary_set, \"r+\") as s:\n",
    "        s.truncate(0)\n",
    "        \n",
    "# nijigen hairetsu ni suru\n",
    "sum_set = summaries.reshape(-1, 1)\n",
    "\n",
    "with open(summary_set, mode='w', newline='', encoding='utf-8') as ss:\n",
    "    w = csv.writer(ss, delimiter='\\t')\n",
    "    w.writerows(sum_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6efc3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1740, 1), (1740,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_set.shape, summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52280c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1740, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>新しい一年が近づき、新しい人との対人関係を築きたい。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>今年7月27日から今日8月12日までロンドンオリンピック関連のロゴに変化していたGoogle記事。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>クリスマスは、思いが叶う新しいパワースポットが、ネットやインターネットで広まりを見せている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>いわゆる「夏日」は夏らしい。特に暑く乾燥した服装で、特に露出したパンツを身に着ける女性は特に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>真夏が到来するなか、夏らしい服装を履く人が増えている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>中途半端な元美人にとって、恋に落ちるのはストレスではない。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>思いがけない話、理解の深まる話。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>人は言う。現代は憎しみと欲だけと。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>日本の金環日食が25年ぶりに行われた。日本の複数メディアが伝えた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>知っ得!虎の巻 は、日本のソーシャルメディアで最も人気を集めている。特に人気なのがTumbl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    c00\n",
       "1738                         新しい一年が近づき、新しい人との対人関係を築きたい。\n",
       "1690  今年7月27日から今日8月12日までロンドンオリンピック関連のロゴに変化していたGoogle記事。\n",
       "812      クリスマスは、思いが叶う新しいパワースポットが、ネットやインターネットで広まりを見せている。\n",
       "864   いわゆる「夏日」は夏らしい。特に暑く乾燥した服装で、特に露出したパンツを身に着ける女性は特に...\n",
       "343                         真夏が到来するなか、夏らしい服装を履く人が増えている。\n",
       "285                       中途半端な元美人にとって、恋に落ちるのはストレスではない。\n",
       "500                                    思いがけない話、理解の深まる話。\n",
       "282                                   人は言う。現代は憎しみと欲だけと。\n",
       "1157                  日本の金環日食が25年ぶりに行われた。日本の複数メディアが伝えた。\n",
       "1674  知っ得!虎の巻 は、日本のソーシャルメディアで最も人気を集めている。特に人気なのがTumbl..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['c{0:02d}'.format(i) for i in range(1)]\n",
    "# データの読み込み\n",
    "s_s = pd.read_csv(\"summary_set_dokujo_it.tsv\", \n",
    "                 delimiter='\\t', names=col_names)\n",
    "# データの確認\n",
    "print(f'データサイズ： {s_s.shape}')\n",
    "s_s.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
