{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637feaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (4.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: sacremoses in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: requests in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: joblib in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: six in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!apt install swig\n",
    "# Sentencepieceのインストール\n",
    "!pip install sentencepiece\n",
    "from transformers import T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
    "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10781bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (1.11.0)\r\n",
      "Requirement already satisfied: typing_extensions in /home/azusa/anaconda3/envs/ai/lib/python3.9/site-packages (from torch) (4.3.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "# GPUが使えれば利用する設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b527e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41cb2c",
   "metadata": {},
   "source": [
    "## data shori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21819e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = '/export/livedoor' \n",
    "#処理をした結果を保存するファイル名 \n",
    "tsv_fname = \"all_text.tsv\" \n",
    "\n",
    "def remove_brackets(inp):\n",
    "    output = re.sub(u'[〃-〿]', '',(re.sub('＝|=|※|×|\\(|\\)|“|”|（|）|／|\\[|\\]| |　|…|・|：|\\n|\\t|/|＜|＞|@|＠', '', re.sub(u'[ℊ-⿻]', '', inp)))) #210A ~ 2FFF\n",
    "    return output\n",
    "\n",
    "def read_title(f):\n",
    "    next(f)\n",
    "    next(f)\n",
    "    title = next(f)\n",
    "    title = remove_brackets(title.encode().decode('utf-8'))\n",
    "    return title[:-1]\n",
    "\n",
    "def read_para(f):\n",
    "    p = ''\n",
    "    while True:\n",
    "        try:\n",
    "            para = next(f)\n",
    "            para = remove_brackets(para.encode().decode('utf-8'))\n",
    "            p += para\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return p [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c66a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ['/export/livedoor/dokujo-tsushin', '/export/livedoor/peachy']\n",
    "target_genre = [\"dokujo-tsushin\", \"peachy\"] \n",
    "zero_fnames = []\n",
    "one_fnames = []\n",
    "\n",
    "if os.path.exists(tsv_fname) == True:\n",
    "    with open(tsv_fname, \"r+\") as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "for i in range(2):\n",
    "    for filename in os.listdir(directory[i]):\n",
    "        if \"LICENSE.txt\" in filename:\n",
    "            continue\n",
    "        f = os.path.join(directory[i], filename)\n",
    "        #if os.path.isfile(f):\n",
    "        #    print(f)\n",
    "        if target_genre[0] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[0], '0', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue\n",
    "        if target_genre[1] in f and f.endswith(\".txt\"):\n",
    "            with open(tsv_fname, \"a\") as wf:\n",
    "                writer = csv.writer(wf, delimiter='\\t')\n",
    "                with open(f) as zf:\n",
    "                    title = read_title(zf)\n",
    "                    para = read_para(zf)\n",
    "                    row = [target_genre[1], '1', title, para]\n",
    "                    writer.writerow(row)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "357bffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1712, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_name</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>オトナ女子のリアルな悩み一生結婚できないのではと不安で</td>\n",
       "      <td>結婚したいと思い続けていても、その予兆すら感じ取れない場合はどうすればいいだろうか。今回の相...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>不運が重なるのはなぜ？独女の嘆</td>\n",
       "      <td>最近、嫌なことばっかり続くんです。踏んだり蹴ったりの毎日で、ツキに見放されたみたいでと弱しく...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>30歳以上の女性にCM出演のチャンス到来!</td>\n",
       "      <td>美容に関する情報感度は誰より鋭い、そんな独女達の必須フードといえるのがヨーグルトだろう。乳酸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>ハートフルなクリスマスケーキはいかが</td>\n",
       "      <td>社会全体になんとなく元気のなかった2009年も、あと2ヶ月で終わり。せめて、締めくくりは、大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>女子力低めでもなぜかモテるWEBメディア女子の実態とは!</td>\n",
       "      <td>ノエビアグループの常盤薬品工業が、2030代の女性特有の慢性トラブル肌に向けたスキンケアブラ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>インタビューコーチ堀口ひとみその人本来の力を引き出</td>\n",
       "      <td>女性が転職を考える時、その理由の大きな一つに数えられる人間関係。どんなに仕事が優秀な人でも、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>インタビュー御影倫代仕事が好きだから、家でも仕事の話がしたい</td>\n",
       "      <td>若い医師たちが過酷な医療現場で、重責を担う仕事に悩み、人間関係に苦しみながらも、一歩ずつ成長...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>peachy</td>\n",
       "      <td>1</td>\n",
       "      <td>ケイトミドルトンのオン＆オフのファッションをCHECK！ロイヤルウェディング特</td>\n",
       "      <td>4月29日にウェストミンスター寺院にて盛大に執り行われたウィリアムズ王子とキャサリン妃の挙式...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>だからモテない!?恋愛下手のダメメー</td>\n",
       "      <td>今や携帯電話のメールは恋愛にとって欠かせないツール。しかし、私たち独女世代が携帯電話を手にし...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>0</td>\n",
       "      <td>オトナ女子のリアルな悩みヨリを戻す約束をして一度別れた彼、今では都合の良い関係</td>\n",
       "      <td>順調だと思い続けていた恋愛が突然急変してしまった場合、誰でも動揺を隠しきれないだろう。今回の...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          media_name  label                                    title  \\\n",
       "668   dokujo-tsushin      0              オトナ女子のリアルな悩み一生結婚できないのではと不安で   \n",
       "466   dokujo-tsushin      0                          不運が重なるのはなぜ？独女の嘆   \n",
       "376   dokujo-tsushin      0                    30歳以上の女性にCM出演のチャンス到来!   \n",
       "891           peachy      1                       ハートフルなクリスマスケーキはいかが   \n",
       "129   dokujo-tsushin      0             女子力低めでもなぜかモテるWEBメディア女子の実態とは!   \n",
       "1201          peachy      1                インタビューコーチ堀口ひとみその人本来の力を引き出   \n",
       "1207          peachy      1           インタビュー御影倫代仕事が好きだから、家でも仕事の話がしたい   \n",
       "1070          peachy      1  ケイトミドルトンのオン＆オフのファッションをCHECK！ロイヤルウェディング特   \n",
       "613   dokujo-tsushin      0                       だからモテない!?恋愛下手のダメメー   \n",
       "768   dokujo-tsushin      0  オトナ女子のリアルな悩みヨリを戻す約束をして一度別れた彼、今では都合の良い関係   \n",
       "\n",
       "                                               sentence  \n",
       "668   結婚したいと思い続けていても、その予兆すら感じ取れない場合はどうすればいいだろうか。今回の相...  \n",
       "466   最近、嫌なことばっかり続くんです。踏んだり蹴ったりの毎日で、ツキに見放されたみたいでと弱しく...  \n",
       "376   美容に関する情報感度は誰より鋭い、そんな独女達の必須フードといえるのがヨーグルトだろう。乳酸...  \n",
       "891   社会全体になんとなく元気のなかった2009年も、あと2ヶ月で終わり。せめて、締めくくりは、大...  \n",
       "129   ノエビアグループの常盤薬品工業が、2030代の女性特有の慢性トラブル肌に向けたスキンケアブラ...  \n",
       "1201  女性が転職を考える時、その理由の大きな一つに数えられる人間関係。どんなに仕事が優秀な人でも、...  \n",
       "1207  若い医師たちが過酷な医療現場で、重責を担う仕事に悩み、人間関係に苦しみながらも、一歩ずつ成長...  \n",
       "1070  4月29日にウェストミンスター寺院にて盛大に執り行われたウィリアムズ王子とキャサリン妃の挙式...  \n",
       "613   今や携帯電話のメールは恋愛にとって欠かせないツール。しかし、私たち独女世代が携帯電話を手にし...  \n",
       "768   順調だと思い続けていた恋愛が突然急変してしまった場合、誰でも動揺を隠しきれないだろう。今回の...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# データの読み込み\n",
    "df = pd.read_csv(\"all_text.tsv\", \n",
    "                 delimiter='\\t', header=None, names=['media_name', 'label','title','sentence'])\n",
    "# データの確認\n",
    "print(f'データサイズ： {df.shape}')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b51fb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = df.media_name.values\n",
    "labels = df.label.values\n",
    "titles = df.title.values\n",
    "sentences = df.sentence.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb6684",
   "metadata": {},
   "source": [
    "## moderu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658f021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_s = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer_s = AutoTokenizer.from_pretrained(model_name_s)\n",
    "model_s = AutoModelForSeq2SeqLM.from_pretrained(model_name_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9c301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = np.zeros(len(sentences), dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9507d3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    article_text = sentences[i]\n",
    "    input_ids = tokenizer_s(\n",
    "        article_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=6000\n",
    "    )[\"input_ids\"]\n",
    "    output_ids = model_s.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=1024,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_beams=4\n",
    "    )[0]\n",
    "    summary = tokenizer_s.decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    summaries[i] = summary\n",
    "    if i % 10 == 0:\n",
    "        print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b692b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summas = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    summas.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(summaries[i])))\n",
    "\n",
    "summas = pd.DataFrame(summas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1a6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大単語数:  72\n",
      "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
     ]
    }
   ],
   "source": [
    "# 最大単語数の確認\n",
    "max_len = []\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    # Tokenizeで分割\n",
    "    token_words = tokenizer.tokenize(summa)\n",
    "    # 文章数を取得してリストへ格納\n",
    "    max_len.append(len(token_words))\n",
    "# 最大の値を確認\n",
    "print('最大単語数: ', max(max_len))\n",
    "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777b2cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  思いがけないことがある人間は、未来を教えてくれることがある。\n",
      "Token IDs: tensor([    9,  2969,    12, 18143,  1272,   858,    11,     7,  3638, 15718,\n",
      "        17379,  1272,     8,     2,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# 1文づつ処理\n",
    "for summa in summaries:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        summa,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = 50,  # I think maximum 文章の長さを固定（Padding/Trancatinating）\n",
    "                        truncation=True,                \n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maksの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "    \n",
    "    # https://qiita.com/YuiKasuga/items/343309257da1798c1b63\n",
    "\n",
    "    # 単語IDを取得    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # Attention　maskの取得\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# tenosor型に変換\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', summaries[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99dbcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数：1540\n",
      "検証データ数:　172 \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# データセットクラスの作成\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# 90%地点のIDを取得\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# データセットを分割\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('訓練データ数：{}'.format(train_size))\n",
    "print('検証データ数:　{} '.format(val_size))\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "\n",
    "# 訓練データローダー\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "# 検証データローダー\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9fdb391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification,AdamW,BertConfig\n",
    "\n",
    "# BertForSequenceClassification 学習済みモデルのロード\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
    "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
    "    output_attentions = False, # アテンションベクトルを出力するか\n",
    "    output_hidden_states = False, # 隠れ層を出力するか\n",
    ")\n",
    "\n",
    "# モデルをGPUへ転送\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8681226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 訓練パートの定義\n",
    "def train(model):\n",
    "    model.train() # 訓練モードで実行\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss\n",
    "\n",
    "# テストパートの定義\n",
    "def validation(model):\n",
    "    model.eval()# 訓練モードをオフ\n",
    "    val_loss = 0\n",
    "    with torch.no_grad(): # 勾配を計算しない\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                (loss, logits) = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebb09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習の実行\n",
    "max_epoch = 10\n",
    "train_loss_ = []\n",
    "test_loss_ = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    train_ = train(model)\n",
    "    test_ = train(model)\n",
    "    train_loss_.append(train_)\n",
    "    test_loss_.append(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd7e4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#correct = 0\n",
    "test_accuracy = 0\n",
    "\n",
    "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
    "\n",
    "model.eval()# 訓練モードをオフ\n",
    "for batch in validation_dataloader:\n",
    "    #print(batch)\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    #print(len(b_labels))\n",
    "    with torch.no_grad():   \n",
    "        # 学習済みモデルによる予測結果をpredsで取得     \n",
    "        preds = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        test_accuracy += (torch.argmax(preds[0]) == b_labels).sum().item() / len(b_labels)\n",
    "\n",
    "        #print(preds[0])\n",
    "        #print(b_labels)\n",
    "\n",
    "print(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b92e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力:SequenceClassifierOutput(loss=None, logits=tensor([[-3.6444,  4.2766],\n",
      "        [-4.4256,  4.9757],\n",
      "        [ 4.3676, -5.2167],\n",
      "        [ 4.2307, -5.1099],\n",
      "        [-4.6130,  5.0120],\n",
      "        [-4.1596,  4.6740],\n",
      "        [ 4.3120, -5.2379],\n",
      "        [-4.6372,  5.0770],\n",
      "        [ 4.2642, -5.0750],\n",
      "        [-4.1218,  4.8760],\n",
      "        [ 4.2240, -5.1450],\n",
      "        [-4.2189,  5.0628]], device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# 予測結果の確認\n",
    "print(f'出力:{preds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7425ef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit_0</th>\n",
       "      <th>logit_1</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.644409</td>\n",
       "      <td>4.276643</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.425563</td>\n",
       "      <td>4.975690</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.367602</td>\n",
       "      <td>-5.216705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.230701</td>\n",
       "      <td>-5.109895</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.612967</td>\n",
       "      <td>5.012002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    logit_0   logit_1  pred_label  true_label\n",
       "0 -3.644409  4.276643           1           0\n",
       "1 -4.425563  4.975690           1           1\n",
       "2  4.367602 -5.216705           0           1\n",
       "3  4.230701 -5.109895           0           0\n",
       "4 -4.612967  5.012002           1           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 比較しやすい様にpd.dataframeへ整形\n",
    "import numpy as np\n",
    "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
    "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
    "## np.argmaxで大き方の値を取得\n",
    "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
    "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
    "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5680f066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(train_loss_)), train_loss_, label=\"Train\")\n",
    "plt.plot(range(len(test_loss_)), test_loss_, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()  # ラベルがあるときは、きちんとplt.show()を呼び出すこと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "851b6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "summary_set = \"summary_set_dokujo_peachy.tsv\" \n",
    "\n",
    "if os.path.exists(summary_set) == True:\n",
    "    with open(summary_set, \"r+\") as s:\n",
    "        s.truncate(0)\n",
    "        \n",
    "# nijigen hairetsu ni suru\n",
    "sum_set = summaries.reshape(-1, 1)\n",
    "\n",
    "with open(summary_set, mode='w', newline='', encoding='utf-8') as ss:\n",
    "    w = csv.writer(ss, delimiter='\\t')\n",
    "    w.writerows(sum_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58ad13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1712, 1), (1712,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_set.shape, summaries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83400383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1712, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>恋愛の達人石田純一さんは、人生のあり方に大きな影響を与えている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>2012年6月29日午前0時(日本時間同日午後1時)から、株式会社サイバーエージェントが運営...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>難読症のマギーキャメロンディアスとローズトニコレット(仮名)がロマンス小説に愛を求めた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>思いも寄らない、前向きに思える。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>負け美女小島慶子(仮名)は現在、東京オリンピックの女子プロレスラーとして活躍している。オリン...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>新型コロナウイルスによる感染症(COVID-19)の流行が続く中、美容整形の専門家たちは、肌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1日間の日程をみてみる。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>春が近づき、新しい一年が到来する。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>思いがけない巡り会いにつながるのか?――。2020年の東京オリンピック(五輪)およびパラリン...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>バレンタインデーは、世界中の恋人に贈るかもしれない。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    c00\n",
       "1321                   恋愛の達人石田純一さんは、人生のあり方に大きな影響を与えている。\n",
       "1382  2012年6月29日午前0時(日本時間同日午後1時)から、株式会社サイバーエージェントが運営...\n",
       "501        難読症のマギーキャメロンディアスとローズトニコレット(仮名)がロマンス小説に愛を求めた。\n",
       "472                                    思いも寄らない、前向きに思える。\n",
       "1392  負け美女小島慶子(仮名)は現在、東京オリンピックの女子プロレスラーとして活躍している。オリン...\n",
       "1123  新型コロナウイルスによる感染症(COVID-19)の流行が続く中、美容整形の専門家たちは、肌...\n",
       "1057                                       1日間の日程をみてみる。\n",
       "924                                   春が近づき、新しい一年が到来する。\n",
       "236   思いがけない巡り会いにつながるのか?――。2020年の東京オリンピック(五輪)およびパラリン...\n",
       "1448                         バレンタインデーは、世界中の恋人に贈るかもしれない。"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['c{0:02d}'.format(i) for i in range(1)]\n",
    "# データの読み込み\n",
    "s_s = pd.read_csv(\"summary_set_dokujo_peachy.tsv\", \n",
    "                 delimiter='\\t', names=col_names)\n",
    "# データの確認\n",
    "print(f'データサイズ： {s_s.shape}')\n",
    "s_s.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
